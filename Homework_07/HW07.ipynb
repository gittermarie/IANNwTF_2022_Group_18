{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03c2cf12",
   "metadata": {},
   "source": [
    "# Homework 07\n",
    "\n",
    "## Assignment 2: Implement LSTM\n",
    "\n",
    "### 2.1 Prepare dataset\n",
    "\n",
    "* MNIST \n",
    "* divide the images up into sequences that will be fed into the model; shape should be (batch, sequencelength, features)\n",
    "* need to alternate the signs of the targets, and implement a cumulative sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "691a5686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Conv2D, AveragePooling2D, TimeDistributed, LSTM, GlobalAvgPool2D, AbstractRNNCell, MaxPooling2D\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import tqdm\n",
    "\n",
    "# magic line only needed in jupyter notebooks!\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3be7f4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dowload data\n",
    "(train_ds, test_ds) = tfds.load('mnist', split=['train', 'test'], as_supervised=True, with_info=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89f8d23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "'''\n",
    "prepare data to be fed into model\n",
    "mnist: loaded raw data\n",
    "batch_size: size of batch, e.g. 32 \n",
    "sequence_length: length of sequence of numbers that will be used for calculations\n",
    "\n",
    "'''\n",
    "def prepare_data(mnist, batch_size, sequence_length):\n",
    "    \n",
    "    # change image datatype from unit8 to tf.float32\n",
    "    mnist = mnist.map(lambda img, target:(tf.cast(img, tf.float32), target))\n",
    "    # normalize values\n",
    "    mnist = mnist.map(lambda img, target: (tf.cast(tf.image.per_image_standardization(img), tf.float32), target))\n",
    "    # batch amount of images depending on the wanted sequence length \n",
    "    mnist_sequence =  mnist.shuffle(1000).batch(sequence_length)\n",
    "\n",
    "    # calculations\n",
    "    # create alternating positve and negative signes of target values and take cummulative sum\n",
    "    \n",
    "    # range to identify which target in the sequence needs with new sign\n",
    "    range_vals = tf.range(sequence_length)\n",
    "    # empty lists to store tensors with sequence of images and new tensor with newly calculated target values\n",
    "    mnist_seq = list()\n",
    "    mnist_targets = list()\n",
    "    # for each sequence of images\n",
    "    for seq in mnist_sequence:\n",
    "        # take old target values\n",
    "        target_digits = seq[-1]\n",
    "        # create alternating signes of target values by checking whether the entry index modulo 2 is zero \n",
    "        # (i.e. even entries are positive, uneven ones negative)\n",
    "        alternating_target_numbers = tf.where(tf.math.floormod(range_vals,2)==0, (target_digits), -(target_digits))\n",
    "        # take cum. sum and cast it to float32\n",
    "        new_target = tf.math.cumsum(alternating_target_numbers)\n",
    "        new_target = tf.cast(new_target, tf.float32)\n",
    "        # add sequence to a list and add new target values to a list (later we will create the new dataset out of those)\n",
    "        mnist_seq.append(seq[0])\n",
    "        mnist_targets.append(new_target)\n",
    "            \n",
    "    # create datasets for image sequences and for targets and then zip the two together\n",
    "    sequences_dataset = tf.data.Dataset.from_tensor_slices(mnist_seq)\n",
    "    targets_dataset = tf.data.Dataset.from_tensor_slices(mnist_targets)\n",
    "    mnist_dataset = tf.data.Dataset.zip((sequences_dataset, targets_dataset))\n",
    "\n",
    "    # cache, batch and prefetch the new dataset\n",
    "    mnist_dataset = mnist_dataset.cache().batch(batch_size).prefetch(10)\n",
    "    \n",
    "    return mnist_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a3778c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(32, 4, 28, 28, 1), dtype=float32, numpy=\n",
       " array([[[[[-0.5673503 ],\n",
       "           [-0.5673503 ],\n",
       "           [-0.5673503 ],\n",
       "           ...,\n",
       "           [-0.5673503 ],\n",
       "           [-0.5673503 ],\n",
       "           [-0.5673503 ]],\n",
       " \n",
       "          [[-0.5673503 ],\n",
       "           [-0.5673503 ],\n",
       "           [-0.5673503 ],\n",
       "           ...,\n",
       "           [-0.5673503 ],\n",
       "           [-0.5673503 ],\n",
       "           [-0.5673503 ]],\n",
       " \n",
       "          [[-0.5673503 ],\n",
       "           [-0.5673503 ],\n",
       "           [-0.5673503 ],\n",
       "           ...,\n",
       "           [-0.5673503 ],\n",
       "           [-0.5673503 ],\n",
       "           [-0.5673503 ]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.5673503 ],\n",
       "           [-0.5673503 ],\n",
       "           [-0.5673503 ],\n",
       "           ...,\n",
       "           [-0.5673503 ],\n",
       "           [-0.5673503 ],\n",
       "           [-0.5673503 ]],\n",
       " \n",
       "          [[-0.5673503 ],\n",
       "           [-0.5673503 ],\n",
       "           [-0.5673503 ],\n",
       "           ...,\n",
       "           [-0.5673503 ],\n",
       "           [-0.5673503 ],\n",
       "           [-0.5673503 ]],\n",
       " \n",
       "          [[-0.5673503 ],\n",
       "           [-0.5673503 ],\n",
       "           [-0.5673503 ],\n",
       "           ...,\n",
       "           [-0.5673503 ],\n",
       "           [-0.5673503 ],\n",
       "           [-0.5673503 ]]],\n",
       " \n",
       " \n",
       "         [[[-0.48898432],\n",
       "           [-0.48898432],\n",
       "           [-0.48898432],\n",
       "           ...,\n",
       "           [-0.48898432],\n",
       "           [-0.48898432],\n",
       "           [-0.48898432]],\n",
       " \n",
       "          [[-0.48898432],\n",
       "           [-0.48898432],\n",
       "           [-0.48898432],\n",
       "           ...,\n",
       "           [-0.48898432],\n",
       "           [-0.48898432],\n",
       "           [-0.48898432]],\n",
       " \n",
       "          [[-0.48898432],\n",
       "           [-0.48898432],\n",
       "           [-0.48898432],\n",
       "           ...,\n",
       "           [-0.48898432],\n",
       "           [-0.48898432],\n",
       "           [-0.48898432]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.48898432],\n",
       "           [-0.48898432],\n",
       "           [-0.48898432],\n",
       "           ...,\n",
       "           [-0.48898432],\n",
       "           [-0.48898432],\n",
       "           [-0.48898432]],\n",
       " \n",
       "          [[-0.48898432],\n",
       "           [-0.48898432],\n",
       "           [-0.48898432],\n",
       "           ...,\n",
       "           [-0.48898432],\n",
       "           [-0.48898432],\n",
       "           [-0.48898432]],\n",
       " \n",
       "          [[-0.48898432],\n",
       "           [-0.48898432],\n",
       "           [-0.48898432],\n",
       "           ...,\n",
       "           [-0.48898432],\n",
       "           [-0.48898432],\n",
       "           [-0.48898432]]],\n",
       " \n",
       " \n",
       "         [[[-0.49979603],\n",
       "           [-0.49979603],\n",
       "           [-0.49979603],\n",
       "           ...,\n",
       "           [-0.49979603],\n",
       "           [-0.49979603],\n",
       "           [-0.49979603]],\n",
       " \n",
       "          [[-0.49979603],\n",
       "           [-0.49979603],\n",
       "           [-0.49979603],\n",
       "           ...,\n",
       "           [-0.49979603],\n",
       "           [-0.49979603],\n",
       "           [-0.49979603]],\n",
       " \n",
       "          [[-0.49979603],\n",
       "           [-0.49979603],\n",
       "           [-0.49979603],\n",
       "           ...,\n",
       "           [-0.49979603],\n",
       "           [-0.49979603],\n",
       "           [-0.49979603]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.49979603],\n",
       "           [-0.49979603],\n",
       "           [-0.49979603],\n",
       "           ...,\n",
       "           [-0.49979603],\n",
       "           [-0.49979603],\n",
       "           [-0.49979603]],\n",
       " \n",
       "          [[-0.49979603],\n",
       "           [-0.49979603],\n",
       "           [-0.49979603],\n",
       "           ...,\n",
       "           [-0.49979603],\n",
       "           [-0.49979603],\n",
       "           [-0.49979603]],\n",
       " \n",
       "          [[-0.49979603],\n",
       "           [-0.49979603],\n",
       "           [-0.49979603],\n",
       "           ...,\n",
       "           [-0.49979603],\n",
       "           [-0.49979603],\n",
       "           [-0.49979603]]],\n",
       " \n",
       " \n",
       "         [[[-0.45139167],\n",
       "           [-0.45139167],\n",
       "           [-0.45139167],\n",
       "           ...,\n",
       "           [-0.45139167],\n",
       "           [-0.45139167],\n",
       "           [-0.45139167]],\n",
       " \n",
       "          [[-0.45139167],\n",
       "           [-0.45139167],\n",
       "           [-0.45139167],\n",
       "           ...,\n",
       "           [-0.45139167],\n",
       "           [-0.45139167],\n",
       "           [-0.45139167]],\n",
       " \n",
       "          [[-0.45139167],\n",
       "           [-0.45139167],\n",
       "           [-0.45139167],\n",
       "           ...,\n",
       "           [-0.45139167],\n",
       "           [-0.45139167],\n",
       "           [-0.45139167]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.45139167],\n",
       "           [-0.45139167],\n",
       "           [-0.45139167],\n",
       "           ...,\n",
       "           [-0.45139167],\n",
       "           [-0.45139167],\n",
       "           [-0.45139167]],\n",
       " \n",
       "          [[-0.45139167],\n",
       "           [-0.45139167],\n",
       "           [-0.45139167],\n",
       "           ...,\n",
       "           [-0.45139167],\n",
       "           [-0.45139167],\n",
       "           [-0.45139167]],\n",
       " \n",
       "          [[-0.45139167],\n",
       "           [-0.45139167],\n",
       "           [-0.45139167],\n",
       "           ...,\n",
       "           [-0.45139167],\n",
       "           [-0.45139167],\n",
       "           [-0.45139167]]]],\n",
       " \n",
       " \n",
       " \n",
       "        [[[[-0.3836283 ],\n",
       "           [-0.3836283 ],\n",
       "           [-0.3836283 ],\n",
       "           ...,\n",
       "           [-0.3836283 ],\n",
       "           [-0.3836283 ],\n",
       "           [-0.3836283 ]],\n",
       " \n",
       "          [[-0.3836283 ],\n",
       "           [-0.3836283 ],\n",
       "           [-0.3836283 ],\n",
       "           ...,\n",
       "           [-0.3836283 ],\n",
       "           [-0.3836283 ],\n",
       "           [-0.3836283 ]],\n",
       " \n",
       "          [[-0.3836283 ],\n",
       "           [-0.3836283 ],\n",
       "           [-0.3836283 ],\n",
       "           ...,\n",
       "           [-0.3836283 ],\n",
       "           [-0.3836283 ],\n",
       "           [-0.3836283 ]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.3836283 ],\n",
       "           [-0.3836283 ],\n",
       "           [-0.3836283 ],\n",
       "           ...,\n",
       "           [-0.3836283 ],\n",
       "           [-0.3836283 ],\n",
       "           [-0.3836283 ]],\n",
       " \n",
       "          [[-0.3836283 ],\n",
       "           [-0.3836283 ],\n",
       "           [-0.3836283 ],\n",
       "           ...,\n",
       "           [-0.3836283 ],\n",
       "           [-0.3836283 ],\n",
       "           [-0.3836283 ]],\n",
       " \n",
       "          [[-0.3836283 ],\n",
       "           [-0.3836283 ],\n",
       "           [-0.3836283 ],\n",
       "           ...,\n",
       "           [-0.3836283 ],\n",
       "           [-0.3836283 ],\n",
       "           [-0.3836283 ]]],\n",
       " \n",
       " \n",
       "         [[[-0.45415196],\n",
       "           [-0.45415196],\n",
       "           [-0.45415196],\n",
       "           ...,\n",
       "           [-0.45415196],\n",
       "           [-0.45415196],\n",
       "           [-0.45415196]],\n",
       " \n",
       "          [[-0.45415196],\n",
       "           [-0.45415196],\n",
       "           [-0.45415196],\n",
       "           ...,\n",
       "           [-0.45415196],\n",
       "           [-0.45415196],\n",
       "           [-0.45415196]],\n",
       " \n",
       "          [[-0.45415196],\n",
       "           [-0.45415196],\n",
       "           [-0.45415196],\n",
       "           ...,\n",
       "           [-0.45415196],\n",
       "           [-0.45415196],\n",
       "           [-0.45415196]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.45415196],\n",
       "           [-0.45415196],\n",
       "           [-0.45415196],\n",
       "           ...,\n",
       "           [-0.45415196],\n",
       "           [-0.45415196],\n",
       "           [-0.45415196]],\n",
       " \n",
       "          [[-0.45415196],\n",
       "           [-0.45415196],\n",
       "           [-0.45415196],\n",
       "           ...,\n",
       "           [-0.45415196],\n",
       "           [-0.45415196],\n",
       "           [-0.45415196]],\n",
       " \n",
       "          [[-0.45415196],\n",
       "           [-0.45415196],\n",
       "           [-0.45415196],\n",
       "           ...,\n",
       "           [-0.45415196],\n",
       "           [-0.45415196],\n",
       "           [-0.45415196]]],\n",
       " \n",
       " \n",
       "         [[[-0.22990851],\n",
       "           [-0.22990851],\n",
       "           [-0.22990851],\n",
       "           ...,\n",
       "           [-0.22990851],\n",
       "           [-0.22990851],\n",
       "           [-0.22990851]],\n",
       " \n",
       "          [[-0.22990851],\n",
       "           [-0.22990851],\n",
       "           [-0.22990851],\n",
       "           ...,\n",
       "           [-0.22990851],\n",
       "           [-0.22990851],\n",
       "           [-0.22990851]],\n",
       " \n",
       "          [[-0.22990851],\n",
       "           [-0.22990851],\n",
       "           [-0.22990851],\n",
       "           ...,\n",
       "           [-0.22990851],\n",
       "           [-0.22990851],\n",
       "           [-0.22990851]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.22990851],\n",
       "           [-0.22990851],\n",
       "           [-0.22990851],\n",
       "           ...,\n",
       "           [-0.22990851],\n",
       "           [-0.22990851],\n",
       "           [-0.22990851]],\n",
       " \n",
       "          [[-0.22990851],\n",
       "           [-0.22990851],\n",
       "           [-0.22990851],\n",
       "           ...,\n",
       "           [-0.22990851],\n",
       "           [-0.22990851],\n",
       "           [-0.22990851]],\n",
       " \n",
       "          [[-0.22990851],\n",
       "           [-0.22990851],\n",
       "           [-0.22990851],\n",
       "           ...,\n",
       "           [-0.22990851],\n",
       "           [-0.22990851],\n",
       "           [-0.22990851]]],\n",
       " \n",
       " \n",
       "         [[[-0.43331113],\n",
       "           [-0.43331113],\n",
       "           [-0.43331113],\n",
       "           ...,\n",
       "           [-0.43331113],\n",
       "           [-0.43331113],\n",
       "           [-0.43331113]],\n",
       " \n",
       "          [[-0.43331113],\n",
       "           [-0.43331113],\n",
       "           [-0.43331113],\n",
       "           ...,\n",
       "           [-0.43331113],\n",
       "           [-0.43331113],\n",
       "           [-0.43331113]],\n",
       " \n",
       "          [[-0.43331113],\n",
       "           [-0.43331113],\n",
       "           [-0.43331113],\n",
       "           ...,\n",
       "           [-0.43331113],\n",
       "           [-0.43331113],\n",
       "           [-0.43331113]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.43331113],\n",
       "           [-0.43331113],\n",
       "           [-0.43331113],\n",
       "           ...,\n",
       "           [-0.43331113],\n",
       "           [-0.43331113],\n",
       "           [-0.43331113]],\n",
       " \n",
       "          [[-0.43331113],\n",
       "           [-0.43331113],\n",
       "           [-0.43331113],\n",
       "           ...,\n",
       "           [-0.43331113],\n",
       "           [-0.43331113],\n",
       "           [-0.43331113]],\n",
       " \n",
       "          [[-0.43331113],\n",
       "           [-0.43331113],\n",
       "           [-0.43331113],\n",
       "           ...,\n",
       "           [-0.43331113],\n",
       "           [-0.43331113],\n",
       "           [-0.43331113]]]],\n",
       " \n",
       " \n",
       " \n",
       "        [[[[-0.36683136],\n",
       "           [-0.36683136],\n",
       "           [-0.36683136],\n",
       "           ...,\n",
       "           [-0.36683136],\n",
       "           [-0.36683136],\n",
       "           [-0.36683136]],\n",
       " \n",
       "          [[-0.36683136],\n",
       "           [-0.36683136],\n",
       "           [-0.36683136],\n",
       "           ...,\n",
       "           [-0.36683136],\n",
       "           [-0.36683136],\n",
       "           [-0.36683136]],\n",
       " \n",
       "          [[-0.36683136],\n",
       "           [-0.36683136],\n",
       "           [-0.36683136],\n",
       "           ...,\n",
       "           [-0.36683136],\n",
       "           [-0.36683136],\n",
       "           [-0.36683136]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.36683136],\n",
       "           [-0.36683136],\n",
       "           [-0.36683136],\n",
       "           ...,\n",
       "           [-0.36683136],\n",
       "           [-0.36683136],\n",
       "           [-0.36683136]],\n",
       " \n",
       "          [[-0.36683136],\n",
       "           [-0.36683136],\n",
       "           [-0.36683136],\n",
       "           ...,\n",
       "           [-0.36683136],\n",
       "           [-0.36683136],\n",
       "           [-0.36683136]],\n",
       " \n",
       "          [[-0.36683136],\n",
       "           [-0.36683136],\n",
       "           [-0.36683136],\n",
       "           ...,\n",
       "           [-0.36683136],\n",
       "           [-0.36683136],\n",
       "           [-0.36683136]]],\n",
       " \n",
       " \n",
       "         [[[-0.47266006],\n",
       "           [-0.47266006],\n",
       "           [-0.47266006],\n",
       "           ...,\n",
       "           [-0.47266006],\n",
       "           [-0.47266006],\n",
       "           [-0.47266006]],\n",
       " \n",
       "          [[-0.47266006],\n",
       "           [-0.47266006],\n",
       "           [-0.47266006],\n",
       "           ...,\n",
       "           [-0.47266006],\n",
       "           [-0.47266006],\n",
       "           [-0.47266006]],\n",
       " \n",
       "          [[-0.47266006],\n",
       "           [-0.47266006],\n",
       "           [-0.47266006],\n",
       "           ...,\n",
       "           [-0.47266006],\n",
       "           [-0.47266006],\n",
       "           [-0.47266006]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.47266006],\n",
       "           [-0.47266006],\n",
       "           [-0.47266006],\n",
       "           ...,\n",
       "           [-0.47266006],\n",
       "           [-0.47266006],\n",
       "           [-0.47266006]],\n",
       " \n",
       "          [[-0.47266006],\n",
       "           [-0.47266006],\n",
       "           [-0.47266006],\n",
       "           ...,\n",
       "           [-0.47266006],\n",
       "           [-0.47266006],\n",
       "           [-0.47266006]],\n",
       " \n",
       "          [[-0.47266006],\n",
       "           [-0.47266006],\n",
       "           [-0.47266006],\n",
       "           ...,\n",
       "           [-0.47266006],\n",
       "           [-0.47266006],\n",
       "           [-0.47266006]]],\n",
       " \n",
       " \n",
       "         [[[-0.3968513 ],\n",
       "           [-0.3968513 ],\n",
       "           [-0.3968513 ],\n",
       "           ...,\n",
       "           [-0.3968513 ],\n",
       "           [-0.3968513 ],\n",
       "           [-0.3968513 ]],\n",
       " \n",
       "          [[-0.3968513 ],\n",
       "           [-0.3968513 ],\n",
       "           [-0.3968513 ],\n",
       "           ...,\n",
       "           [-0.3968513 ],\n",
       "           [-0.3968513 ],\n",
       "           [-0.3968513 ]],\n",
       " \n",
       "          [[-0.3968513 ],\n",
       "           [-0.3968513 ],\n",
       "           [-0.3968513 ],\n",
       "           ...,\n",
       "           [-0.3968513 ],\n",
       "           [-0.3968513 ],\n",
       "           [-0.3968513 ]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.3968513 ],\n",
       "           [-0.3968513 ],\n",
       "           [-0.3968513 ],\n",
       "           ...,\n",
       "           [-0.3968513 ],\n",
       "           [-0.3968513 ],\n",
       "           [-0.3968513 ]],\n",
       " \n",
       "          [[-0.3968513 ],\n",
       "           [-0.3968513 ],\n",
       "           [-0.3968513 ],\n",
       "           ...,\n",
       "           [-0.3968513 ],\n",
       "           [-0.3968513 ],\n",
       "           [-0.3968513 ]],\n",
       " \n",
       "          [[-0.3968513 ],\n",
       "           [-0.3968513 ],\n",
       "           [-0.3968513 ],\n",
       "           ...,\n",
       "           [-0.3968513 ],\n",
       "           [-0.3968513 ],\n",
       "           [-0.3968513 ]]],\n",
       " \n",
       " \n",
       "         [[[-0.42563564],\n",
       "           [-0.42563564],\n",
       "           [-0.42563564],\n",
       "           ...,\n",
       "           [-0.42563564],\n",
       "           [-0.42563564],\n",
       "           [-0.42563564]],\n",
       " \n",
       "          [[-0.42563564],\n",
       "           [-0.42563564],\n",
       "           [-0.42563564],\n",
       "           ...,\n",
       "           [-0.42563564],\n",
       "           [-0.42563564],\n",
       "           [-0.42563564]],\n",
       " \n",
       "          [[-0.42563564],\n",
       "           [-0.42563564],\n",
       "           [-0.42563564],\n",
       "           ...,\n",
       "           [-0.42563564],\n",
       "           [-0.42563564],\n",
       "           [-0.42563564]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.42563564],\n",
       "           [-0.42563564],\n",
       "           [-0.42563564],\n",
       "           ...,\n",
       "           [-0.42563564],\n",
       "           [-0.42563564],\n",
       "           [-0.42563564]],\n",
       " \n",
       "          [[-0.42563564],\n",
       "           [-0.42563564],\n",
       "           [-0.42563564],\n",
       "           ...,\n",
       "           [-0.42563564],\n",
       "           [-0.42563564],\n",
       "           [-0.42563564]],\n",
       " \n",
       "          [[-0.42563564],\n",
       "           [-0.42563564],\n",
       "           [-0.42563564],\n",
       "           ...,\n",
       "           [-0.42563564],\n",
       "           [-0.42563564],\n",
       "           [-0.42563564]]]],\n",
       " \n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       " \n",
       "        [[[[-0.4914939 ],\n",
       "           [-0.4914939 ],\n",
       "           [-0.4914939 ],\n",
       "           ...,\n",
       "           [-0.4914939 ],\n",
       "           [-0.4914939 ],\n",
       "           [-0.4914939 ]],\n",
       " \n",
       "          [[-0.4914939 ],\n",
       "           [-0.4914939 ],\n",
       "           [-0.4914939 ],\n",
       "           ...,\n",
       "           [-0.4914939 ],\n",
       "           [-0.4914939 ],\n",
       "           [-0.4914939 ]],\n",
       " \n",
       "          [[-0.4914939 ],\n",
       "           [-0.4914939 ],\n",
       "           [-0.4914939 ],\n",
       "           ...,\n",
       "           [-0.4914939 ],\n",
       "           [-0.4914939 ],\n",
       "           [-0.4914939 ]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.4914939 ],\n",
       "           [-0.4914939 ],\n",
       "           [-0.4914939 ],\n",
       "           ...,\n",
       "           [-0.4914939 ],\n",
       "           [-0.4914939 ],\n",
       "           [-0.4914939 ]],\n",
       " \n",
       "          [[-0.4914939 ],\n",
       "           [-0.4914939 ],\n",
       "           [-0.4914939 ],\n",
       "           ...,\n",
       "           [-0.4914939 ],\n",
       "           [-0.4914939 ],\n",
       "           [-0.4914939 ]],\n",
       " \n",
       "          [[-0.4914939 ],\n",
       "           [-0.4914939 ],\n",
       "           [-0.4914939 ],\n",
       "           ...,\n",
       "           [-0.4914939 ],\n",
       "           [-0.4914939 ],\n",
       "           [-0.4914939 ]]],\n",
       " \n",
       " \n",
       "         [[[-0.40258786],\n",
       "           [-0.40258786],\n",
       "           [-0.40258786],\n",
       "           ...,\n",
       "           [-0.40258786],\n",
       "           [-0.40258786],\n",
       "           [-0.40258786]],\n",
       " \n",
       "          [[-0.40258786],\n",
       "           [-0.40258786],\n",
       "           [-0.40258786],\n",
       "           ...,\n",
       "           [-0.40258786],\n",
       "           [-0.40258786],\n",
       "           [-0.40258786]],\n",
       " \n",
       "          [[-0.40258786],\n",
       "           [-0.40258786],\n",
       "           [-0.40258786],\n",
       "           ...,\n",
       "           [-0.40258786],\n",
       "           [-0.40258786],\n",
       "           [-0.40258786]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.40258786],\n",
       "           [-0.40258786],\n",
       "           [-0.40258786],\n",
       "           ...,\n",
       "           [-0.40258786],\n",
       "           [-0.40258786],\n",
       "           [-0.40258786]],\n",
       " \n",
       "          [[-0.40258786],\n",
       "           [-0.40258786],\n",
       "           [-0.40258786],\n",
       "           ...,\n",
       "           [-0.40258786],\n",
       "           [-0.40258786],\n",
       "           [-0.40258786]],\n",
       " \n",
       "          [[-0.40258786],\n",
       "           [-0.40258786],\n",
       "           [-0.40258786],\n",
       "           ...,\n",
       "           [-0.40258786],\n",
       "           [-0.40258786],\n",
       "           [-0.40258786]]],\n",
       " \n",
       " \n",
       "         [[[-0.52599025],\n",
       "           [-0.52599025],\n",
       "           [-0.52599025],\n",
       "           ...,\n",
       "           [-0.52599025],\n",
       "           [-0.52599025],\n",
       "           [-0.52599025]],\n",
       " \n",
       "          [[-0.52599025],\n",
       "           [-0.52599025],\n",
       "           [-0.52599025],\n",
       "           ...,\n",
       "           [-0.52599025],\n",
       "           [-0.52599025],\n",
       "           [-0.52599025]],\n",
       " \n",
       "          [[-0.52599025],\n",
       "           [-0.52599025],\n",
       "           [-0.52599025],\n",
       "           ...,\n",
       "           [-0.52599025],\n",
       "           [-0.52599025],\n",
       "           [-0.52599025]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.52599025],\n",
       "           [-0.52599025],\n",
       "           [-0.52599025],\n",
       "           ...,\n",
       "           [-0.52599025],\n",
       "           [-0.52599025],\n",
       "           [-0.52599025]],\n",
       " \n",
       "          [[-0.52599025],\n",
       "           [-0.52599025],\n",
       "           [-0.52599025],\n",
       "           ...,\n",
       "           [-0.52599025],\n",
       "           [-0.52599025],\n",
       "           [-0.52599025]],\n",
       " \n",
       "          [[-0.52599025],\n",
       "           [-0.52599025],\n",
       "           [-0.52599025],\n",
       "           ...,\n",
       "           [-0.52599025],\n",
       "           [-0.52599025],\n",
       "           [-0.52599025]]],\n",
       " \n",
       " \n",
       "         [[[-0.4563187 ],\n",
       "           [-0.4563187 ],\n",
       "           [-0.4563187 ],\n",
       "           ...,\n",
       "           [-0.4563187 ],\n",
       "           [-0.4563187 ],\n",
       "           [-0.4563187 ]],\n",
       " \n",
       "          [[-0.4563187 ],\n",
       "           [-0.4563187 ],\n",
       "           [-0.4563187 ],\n",
       "           ...,\n",
       "           [-0.4563187 ],\n",
       "           [-0.4563187 ],\n",
       "           [-0.4563187 ]],\n",
       " \n",
       "          [[-0.4563187 ],\n",
       "           [-0.4563187 ],\n",
       "           [-0.4563187 ],\n",
       "           ...,\n",
       "           [-0.4563187 ],\n",
       "           [-0.4563187 ],\n",
       "           [-0.4563187 ]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.4563187 ],\n",
       "           [-0.4563187 ],\n",
       "           [-0.4563187 ],\n",
       "           ...,\n",
       "           [-0.4563187 ],\n",
       "           [-0.4563187 ],\n",
       "           [-0.4563187 ]],\n",
       " \n",
       "          [[-0.4563187 ],\n",
       "           [-0.4563187 ],\n",
       "           [-0.4563187 ],\n",
       "           ...,\n",
       "           [-0.4563187 ],\n",
       "           [-0.4563187 ],\n",
       "           [-0.4563187 ]],\n",
       " \n",
       "          [[-0.4563187 ],\n",
       "           [-0.4563187 ],\n",
       "           [-0.4563187 ],\n",
       "           ...,\n",
       "           [-0.4563187 ],\n",
       "           [-0.4563187 ],\n",
       "           [-0.4563187 ]]]],\n",
       " \n",
       " \n",
       " \n",
       "        [[[[-0.3642126 ],\n",
       "           [-0.3642126 ],\n",
       "           [-0.3642126 ],\n",
       "           ...,\n",
       "           [-0.3642126 ],\n",
       "           [-0.3642126 ],\n",
       "           [-0.3642126 ]],\n",
       " \n",
       "          [[-0.3642126 ],\n",
       "           [-0.3642126 ],\n",
       "           [-0.3642126 ],\n",
       "           ...,\n",
       "           [-0.3642126 ],\n",
       "           [-0.3642126 ],\n",
       "           [-0.3642126 ]],\n",
       " \n",
       "          [[-0.3642126 ],\n",
       "           [-0.3642126 ],\n",
       "           [-0.3642126 ],\n",
       "           ...,\n",
       "           [-0.3642126 ],\n",
       "           [-0.3642126 ],\n",
       "           [-0.3642126 ]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.3642126 ],\n",
       "           [-0.3642126 ],\n",
       "           [-0.3642126 ],\n",
       "           ...,\n",
       "           [-0.3642126 ],\n",
       "           [-0.3642126 ],\n",
       "           [-0.3642126 ]],\n",
       " \n",
       "          [[-0.3642126 ],\n",
       "           [-0.3642126 ],\n",
       "           [-0.3642126 ],\n",
       "           ...,\n",
       "           [-0.3642126 ],\n",
       "           [-0.3642126 ],\n",
       "           [-0.3642126 ]],\n",
       " \n",
       "          [[-0.3642126 ],\n",
       "           [-0.3642126 ],\n",
       "           [-0.3642126 ],\n",
       "           ...,\n",
       "           [-0.3642126 ],\n",
       "           [-0.3642126 ],\n",
       "           [-0.3642126 ]]],\n",
       " \n",
       " \n",
       "         [[[-0.45569596],\n",
       "           [-0.45569596],\n",
       "           [-0.45569596],\n",
       "           ...,\n",
       "           [-0.45569596],\n",
       "           [-0.45569596],\n",
       "           [-0.45569596]],\n",
       " \n",
       "          [[-0.45569596],\n",
       "           [-0.45569596],\n",
       "           [-0.45569596],\n",
       "           ...,\n",
       "           [-0.45569596],\n",
       "           [-0.45569596],\n",
       "           [-0.45569596]],\n",
       " \n",
       "          [[-0.45569596],\n",
       "           [-0.45569596],\n",
       "           [-0.45569596],\n",
       "           ...,\n",
       "           [-0.45569596],\n",
       "           [-0.45569596],\n",
       "           [-0.45569596]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.45569596],\n",
       "           [-0.45569596],\n",
       "           [-0.45569596],\n",
       "           ...,\n",
       "           [-0.45569596],\n",
       "           [-0.45569596],\n",
       "           [-0.45569596]],\n",
       " \n",
       "          [[-0.45569596],\n",
       "           [-0.45569596],\n",
       "           [-0.45569596],\n",
       "           ...,\n",
       "           [-0.45569596],\n",
       "           [-0.45569596],\n",
       "           [-0.45569596]],\n",
       " \n",
       "          [[-0.45569596],\n",
       "           [-0.45569596],\n",
       "           [-0.45569596],\n",
       "           ...,\n",
       "           [-0.45569596],\n",
       "           [-0.45569596],\n",
       "           [-0.45569596]]],\n",
       " \n",
       " \n",
       "         [[[-0.6170508 ],\n",
       "           [-0.6170508 ],\n",
       "           [-0.6170508 ],\n",
       "           ...,\n",
       "           [-0.6170508 ],\n",
       "           [-0.6170508 ],\n",
       "           [-0.6170508 ]],\n",
       " \n",
       "          [[-0.6170508 ],\n",
       "           [-0.6170508 ],\n",
       "           [-0.6170508 ],\n",
       "           ...,\n",
       "           [-0.6170508 ],\n",
       "           [-0.6170508 ],\n",
       "           [-0.6170508 ]],\n",
       " \n",
       "          [[-0.6170508 ],\n",
       "           [-0.6170508 ],\n",
       "           [-0.6170508 ],\n",
       "           ...,\n",
       "           [-0.6170508 ],\n",
       "           [-0.6170508 ],\n",
       "           [-0.6170508 ]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.6170508 ],\n",
       "           [-0.6170508 ],\n",
       "           [-0.6170508 ],\n",
       "           ...,\n",
       "           [-0.6170508 ],\n",
       "           [-0.6170508 ],\n",
       "           [-0.6170508 ]],\n",
       " \n",
       "          [[-0.6170508 ],\n",
       "           [-0.6170508 ],\n",
       "           [-0.6170508 ],\n",
       "           ...,\n",
       "           [-0.6170508 ],\n",
       "           [-0.6170508 ],\n",
       "           [-0.6170508 ]],\n",
       " \n",
       "          [[-0.6170508 ],\n",
       "           [-0.6170508 ],\n",
       "           [-0.6170508 ],\n",
       "           ...,\n",
       "           [-0.6170508 ],\n",
       "           [-0.6170508 ],\n",
       "           [-0.6170508 ]]],\n",
       " \n",
       " \n",
       "         [[[-0.33228275],\n",
       "           [-0.33228275],\n",
       "           [-0.33228275],\n",
       "           ...,\n",
       "           [-0.33228275],\n",
       "           [-0.33228275],\n",
       "           [-0.33228275]],\n",
       " \n",
       "          [[-0.33228275],\n",
       "           [-0.33228275],\n",
       "           [-0.33228275],\n",
       "           ...,\n",
       "           [-0.33228275],\n",
       "           [-0.33228275],\n",
       "           [-0.33228275]],\n",
       " \n",
       "          [[-0.33228275],\n",
       "           [-0.33228275],\n",
       "           [-0.33228275],\n",
       "           ...,\n",
       "           [-0.33228275],\n",
       "           [-0.33228275],\n",
       "           [-0.33228275]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.33228275],\n",
       "           [-0.33228275],\n",
       "           [-0.33228275],\n",
       "           ...,\n",
       "           [-0.33228275],\n",
       "           [-0.33228275],\n",
       "           [-0.33228275]],\n",
       " \n",
       "          [[-0.33228275],\n",
       "           [-0.33228275],\n",
       "           [-0.33228275],\n",
       "           ...,\n",
       "           [-0.33228275],\n",
       "           [-0.33228275],\n",
       "           [-0.33228275]],\n",
       " \n",
       "          [[-0.33228275],\n",
       "           [-0.33228275],\n",
       "           [-0.33228275],\n",
       "           ...,\n",
       "           [-0.33228275],\n",
       "           [-0.33228275],\n",
       "           [-0.33228275]]]],\n",
       " \n",
       " \n",
       " \n",
       "        [[[[-0.34742305],\n",
       "           [-0.34742305],\n",
       "           [-0.34742305],\n",
       "           ...,\n",
       "           [-0.34742305],\n",
       "           [-0.34742305],\n",
       "           [-0.34742305]],\n",
       " \n",
       "          [[-0.34742305],\n",
       "           [-0.34742305],\n",
       "           [-0.34742305],\n",
       "           ...,\n",
       "           [-0.34742305],\n",
       "           [-0.34742305],\n",
       "           [-0.34742305]],\n",
       " \n",
       "          [[-0.34742305],\n",
       "           [-0.34742305],\n",
       "           [-0.34742305],\n",
       "           ...,\n",
       "           [-0.34742305],\n",
       "           [-0.34742305],\n",
       "           [-0.34742305]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.34742305],\n",
       "           [-0.34742305],\n",
       "           [-0.34742305],\n",
       "           ...,\n",
       "           [-0.34742305],\n",
       "           [-0.34742305],\n",
       "           [-0.34742305]],\n",
       " \n",
       "          [[-0.34742305],\n",
       "           [-0.34742305],\n",
       "           [-0.34742305],\n",
       "           ...,\n",
       "           [-0.34742305],\n",
       "           [-0.34742305],\n",
       "           [-0.34742305]],\n",
       " \n",
       "          [[-0.34742305],\n",
       "           [-0.34742305],\n",
       "           [-0.34742305],\n",
       "           ...,\n",
       "           [-0.34742305],\n",
       "           [-0.34742305],\n",
       "           [-0.34742305]]],\n",
       " \n",
       " \n",
       "         [[[-0.39962152],\n",
       "           [-0.39962152],\n",
       "           [-0.39962152],\n",
       "           ...,\n",
       "           [-0.39962152],\n",
       "           [-0.39962152],\n",
       "           [-0.39962152]],\n",
       " \n",
       "          [[-0.39962152],\n",
       "           [-0.39962152],\n",
       "           [-0.39962152],\n",
       "           ...,\n",
       "           [-0.39962152],\n",
       "           [-0.39962152],\n",
       "           [-0.39962152]],\n",
       " \n",
       "          [[-0.39962152],\n",
       "           [-0.39962152],\n",
       "           [-0.39962152],\n",
       "           ...,\n",
       "           [-0.39962152],\n",
       "           [-0.39962152],\n",
       "           [-0.39962152]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.39962152],\n",
       "           [-0.39962152],\n",
       "           [-0.39962152],\n",
       "           ...,\n",
       "           [-0.39962152],\n",
       "           [-0.39962152],\n",
       "           [-0.39962152]],\n",
       " \n",
       "          [[-0.39962152],\n",
       "           [-0.39962152],\n",
       "           [-0.39962152],\n",
       "           ...,\n",
       "           [-0.39962152],\n",
       "           [-0.39962152],\n",
       "           [-0.39962152]],\n",
       " \n",
       "          [[-0.39962152],\n",
       "           [-0.39962152],\n",
       "           [-0.39962152],\n",
       "           ...,\n",
       "           [-0.39962152],\n",
       "           [-0.39962152],\n",
       "           [-0.39962152]]],\n",
       " \n",
       " \n",
       "         [[[-0.43134114],\n",
       "           [-0.43134114],\n",
       "           [-0.43134114],\n",
       "           ...,\n",
       "           [-0.43134114],\n",
       "           [-0.43134114],\n",
       "           [-0.43134114]],\n",
       " \n",
       "          [[-0.43134114],\n",
       "           [-0.43134114],\n",
       "           [-0.43134114],\n",
       "           ...,\n",
       "           [-0.43134114],\n",
       "           [-0.43134114],\n",
       "           [-0.43134114]],\n",
       " \n",
       "          [[-0.43134114],\n",
       "           [-0.43134114],\n",
       "           [-0.43134114],\n",
       "           ...,\n",
       "           [-0.43134114],\n",
       "           [-0.43134114],\n",
       "           [-0.43134114]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.43134114],\n",
       "           [-0.43134114],\n",
       "           [-0.43134114],\n",
       "           ...,\n",
       "           [-0.43134114],\n",
       "           [-0.43134114],\n",
       "           [-0.43134114]],\n",
       " \n",
       "          [[-0.43134114],\n",
       "           [-0.43134114],\n",
       "           [-0.43134114],\n",
       "           ...,\n",
       "           [-0.43134114],\n",
       "           [-0.43134114],\n",
       "           [-0.43134114]],\n",
       " \n",
       "          [[-0.43134114],\n",
       "           [-0.43134114],\n",
       "           [-0.43134114],\n",
       "           ...,\n",
       "           [-0.43134114],\n",
       "           [-0.43134114],\n",
       "           [-0.43134114]]],\n",
       " \n",
       " \n",
       "         [[[-0.53584105],\n",
       "           [-0.53584105],\n",
       "           [-0.53584105],\n",
       "           ...,\n",
       "           [-0.53584105],\n",
       "           [-0.53584105],\n",
       "           [-0.53584105]],\n",
       " \n",
       "          [[-0.53584105],\n",
       "           [-0.53584105],\n",
       "           [-0.53584105],\n",
       "           ...,\n",
       "           [-0.53584105],\n",
       "           [-0.53584105],\n",
       "           [-0.53584105]],\n",
       " \n",
       "          [[-0.53584105],\n",
       "           [-0.53584105],\n",
       "           [-0.53584105],\n",
       "           ...,\n",
       "           [-0.53584105],\n",
       "           [-0.53584105],\n",
       "           [-0.53584105]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.53584105],\n",
       "           [-0.53584105],\n",
       "           [-0.53584105],\n",
       "           ...,\n",
       "           [-0.53584105],\n",
       "           [-0.53584105],\n",
       "           [-0.53584105]],\n",
       " \n",
       "          [[-0.53584105],\n",
       "           [-0.53584105],\n",
       "           [-0.53584105],\n",
       "           ...,\n",
       "           [-0.53584105],\n",
       "           [-0.53584105],\n",
       "           [-0.53584105]],\n",
       " \n",
       "          [[-0.53584105],\n",
       "           [-0.53584105],\n",
       "           [-0.53584105],\n",
       "           ...,\n",
       "           [-0.53584105],\n",
       "           [-0.53584105],\n",
       "           [-0.53584105]]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(32, 4), dtype=float32, numpy=\n",
       " array([[  0.,  -5.,   2.,  -3.],\n",
       "        [  5.,   5.,   6.,   4.],\n",
       "        [  2.,   0.,   4.,   4.],\n",
       "        [  6.,   4.,   4.,  -1.],\n",
       "        [  1.,  -3.,   5.,   4.],\n",
       "        [  5.,  -2.,  -2.,  -6.],\n",
       "        [  6.,   5.,   5.,  -1.],\n",
       "        [  2.,  -4.,   4.,  -4.],\n",
       "        [  8.,   2.,   4.,   0.],\n",
       "        [  1.,  -3.,  -2.,  -4.],\n",
       "        [  9.,   2.,   4.,  -3.],\n",
       "        [  9.,   3.,  11.,  10.],\n",
       "        [  9.,   2.,   6.,   3.],\n",
       "        [  5.,  -3.,   1.,  -8.],\n",
       "        [  9.,   1.,   3.,   3.],\n",
       "        [  6.,   5.,   9.,   4.],\n",
       "        [  8.,  -1.,   8.,   0.],\n",
       "        [  3.,   2.,   4.,  -3.],\n",
       "        [  4.,  -3.,  -3., -11.],\n",
       "        [  3.,   3.,  12.,   9.],\n",
       "        [  0.,  -6.,  -5.,  -9.],\n",
       "        [  8.,   8.,  16.,  15.],\n",
       "        [  4.,   3.,   3.,  -4.],\n",
       "        [  1.,   0.,   2.,  -1.],\n",
       "        [  0.,  -4.,  -1.,  -5.],\n",
       "        [  3.,   1.,   3.,   2.],\n",
       "        [  2.,   2.,   3.,  -3.],\n",
       "        [  4.,  -5.,   3.,  -1.],\n",
       "        [  0.,  -4.,  -4.,  -5.],\n",
       "        [  0.,  -2.,   0.,  -8.],\n",
       "        [  4.,  -4.,   4.,  -5.],\n",
       "        [  7.,   2.,   7.,   7.]], dtype=float32)>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create training and testing data sets \n",
    "train_dataset = prepare_data(train_ds, 32, 4)\n",
    "test_dataset = prepare_data(test_ds, 32, 4)\n",
    "\n",
    "# print how a batch looks like\n",
    "iterator = iter(train_dataset)\n",
    "iterator.get_next()\n",
    "\n",
    "# the current shape is ((tensor with images), (tensor with target values)) \n",
    "# and they have the shape ((32, 4, 28, 28, 1), (32, 4))\n",
    "# not sure if that is how we want it to? or should the new target values be inside the first tensor ? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0b83f3",
   "metadata": {},
   "source": [
    "### 2.2 CNN and LSTM Network\n",
    "\n",
    "* first part: basic CNN structure\n",
    "* should extract vector representations from each MNIST image using Conv2D layers as well as (global) pooling or Flatten layers\n",
    "* Conv2D layer can be called on a batch of sequences of images, where the time dimension is in the second axis; time dimension will then be processed like a second batch dimension -> extended batch shape\n",
    "* while Conv2D layers accept a (batch, sequence-length, image) data structure with their extended batch size functionality, for the pooling layers to work correctly they need to be wrapped in TensorFlowâ€™s TimeDistributed layers!\n",
    "* Once all images are encoded as vectors, the shape of the tensor should be (batch, sequence-length, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ad2dfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):  \n",
    "        super().__init__()\n",
    "        \n",
    "        # layers\n",
    "        self.conv1 = TimeDistributed(Conv2D(filters=24, kernel_size=3, padding='same', activation='relu'))\n",
    "        self.conv2 = TimeDistributed(Conv2D(filters=24, kernel_size=3, padding='same', activation='relu'))\n",
    "        self.maxpool = TimeDistributed(MaxPooling2D(pool_size=2, strides=2))\n",
    "\n",
    "        self.conv3 = TimeDistributed(Conv2D(filters=48, kernel_size=3, padding='same', activation='relu'))\n",
    "        self.conv4 = TimeDistributed(Conv2D(filters=48, kernel_size=3, padding='same', activation='relu'))\n",
    "        self.globalpool = TimeDistributed(GlobalAvgPool2D())\n",
    "\n",
    "        self.out = TimeDistributed(Dense(10, activation='softmax'))\n",
    "        \n",
    "    @tf.function\n",
    "    def __call__(self, x, training=False):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.globalpool(x)\n",
    "        \n",
    "        x = self.out(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeef945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f64c621b",
   "metadata": {},
   "source": [
    "### 2.3 LSTM AbstractRNNcell layer\n",
    "\n",
    "* subclass the AbstractRNNCell layer and implement its methods and define the required properties (state size, output size, and get initial state, which determines the initial hidden and cell state of the LSTM (usually tensors filled with zeros))\n",
    "* LSTM-cell layerâ€™s call method should take one (batch of) feature vector(s) as its input, along with the â€statesâ€, a list containing the different state tensors of the LSTM cell (cell state and hidden state!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676d747f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(tf.keras.layers.AbstractRNNCell):\n",
    "\n",
    "    def __init__(self, num_hidden_states, num_cell_states, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.hidden_states = num_hidden_states\n",
    "        self.cell_states = num_cell_states\n",
    "        # ? \n",
    "        self.layer1 = tf.keras.layers.Dense(cell_states)\n",
    "        self.layer2 = tf.keras.layers.Dense(hidden_states)\n",
    "        \n",
    "        # first recurrent layer in the RNN\n",
    "        self.recurrent_layer_1 = tf.keras.layers.Dense(recurrent_units_1, \n",
    "                                                       kernel_initializer= tf.keras.initializers.Orthogonal(\n",
    "                                                           gain=1.0, seed=None),\n",
    "                                                       activation=tf.nn.tanh)\n",
    "        # layer normalization for trainability\n",
    "        self.layer_norm_1 = tf.keras.layers.LayerNormalization()\n",
    "        \n",
    "        # second recurrent layer in the RNN\n",
    "        self.recurrent_layer_2 = tf.keras.layers.Dense(recurrent_units_2, \n",
    "                                                       kernel_initializer= tf.keras.initializers.Orthogonal(\n",
    "                                                           gain=1.0, seed=None), \n",
    "                                                       activation=tf.nn.tanh)\n",
    "        # layer normalization for trainability\n",
    "        self.layer_norm_2 = tf.keras.layers.LayerNormalization()\n",
    "    \n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return [tf.TensorShape([self.recurrent_units_1]), \n",
    "                tf.TensorShape([self.recurrent_units_2])]\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return [tf.TensorShape([self.recurrent_units_2])]\n",
    "    \n",
    "    def get_initial_state(self, inputs=None, batch_size=None, dtype=None):\n",
    "        return [tf.zeros([self.recurrent_units_1]), \n",
    "                tf.zeros([self.recurrent_units_2])]\n",
    "\n",
    "    # call method takes (batch of) feature vector(s) as its input, along with the â€statesâ€ \n",
    "    def call(self, inputs, states):\n",
    "        \n",
    "        hidden_state = states[0]\n",
    "        cell_state = states[1]\n",
    "        \n",
    "        # linearly project input\n",
    "        x = self.linear_1(inputs) + state_layer_1\n",
    "        \n",
    "        # apply first recurrent kernel\n",
    "        new_state_layer_1 = self.recurrent_layer_1(x)\n",
    "        \n",
    "        # apply layer norm\n",
    "        x = self.layer_norm_1(new_state_layer_1)\n",
    "        \n",
    "        # linearly project output of layer norm\n",
    "        x = self.linear_2(x) + state_layer_2\n",
    "        \n",
    "        # apply second recurrent layer\n",
    "        new_state_layer_2 = self.recurrent_layer_2(x)\n",
    "        \n",
    "        # apply second layer's layer norm\n",
    "        x = self.layer_norm_2(new_state_layer_2)\n",
    "        \n",
    "        # return output and the list of new states of the layers\n",
    "        return x, [new_state_layer_1, new_state_layer_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8a57ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70662eab",
   "metadata": {},
   "source": [
    "### 2.4 Wrapping LSTM Cell layer with RNN layer\n",
    "\n",
    "* tf.keras.layers.RNN takes an instance of your LSTM cell as the first argument in its constructor\n",
    "* the â€wrapperâ€ RNN layer then takes the sequence of vector representations of the mnist images as its input (batch, seq len, feature dim)\n",
    "* need to specify whether you want the RNN wrapper layer to return the output of your LSTM-cell for every time-step or only for the last step (with the argument return sequences=True) -> generally task-dependent (so think about what makes sense here)\n",
    "* for speed-ups (at the cost of memory usage), set the â€unrollâ€ argument to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3fcf88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc4e8db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e197618",
   "metadata": {},
   "source": [
    "### 2.5 Computing model output\n",
    "\n",
    "* could (if the task demands it) use the same Dense layer to predict targets for all time-steps; but likely do not want to have a Dense layer for each time-stepâ€™s target prediction (potential for overfitting!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c4f591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57a7b74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b77616b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "478ebae9",
   "metadata": {},
   "source": [
    "### 2.6 Training\n",
    "\n",
    "* own training loop or model.compile and model.fit methods\n",
    "* track experiments properly, save configs (e.g. hyperparameters) of settings, save logs (e.g. with Tensorboard) and checkpoint the modelâ€™s weights (or even the complete model)\n",
    "* visualize your results (e.g default history callback of model.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f30913a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25ac223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08f5725b",
   "metadata": {},
   "source": [
    "### 2.7 Questions\n",
    "\n",
    "* try out: initialize your LSTMâ€™s recurrent kernels with the orthogonal initializer: tf.keras.initializers.Orthogonal\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iannwtf",
   "language": "python",
   "name": "iannwtf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
