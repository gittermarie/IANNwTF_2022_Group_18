{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework 07\n",
    "## Assignment 2: Implement LSTM\n",
    "# 2.1 Prepare dataset\n",
    "- MNIST\n",
    "- divide the images up into sequences that will be fed into the model; shape should be (batch, sequencelength, features)\n",
    "- need to alternate the signs of the targets, and implement a cumulative sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Conv2D, AveragePooling2D, TimeDistributed, LSTM, GlobalAvgPool2D, AbstractRNNCell, MaxPooling2D, RNN\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import tqdm\n",
    "\n",
    "# magic line only needed in jupyter notebooks!\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_ds, test_ds) = tfds.load('mnist', split=['train', 'test'], as_supervised=True, with_info=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(mnist, batch_size, sequence_length):\n",
    "    \n",
    "    # change image datatype from unit8 to tf.float32\n",
    "    mnist = mnist.map(lambda img, target:(tf.cast(img, tf.float32), target))\n",
    "    # normalize values\n",
    "    mnist = mnist.map(lambda img, target: (tf.cast(tf.image.per_image_standardization(img), tf.float32), target))\n",
    "    # batch amount of images depending on the wanted sequence length \n",
    "    mnist_sequence =  mnist.shuffle(1000).batch(sequence_length)\n",
    "\n",
    "    # calculations\n",
    "    # create alternating positve and negative signes of target values and take cummulative sum\n",
    "    \n",
    "    # range to identify which target in the sequence needs with new sign\n",
    "    range_vals = tf.range(sequence_length)\n",
    "    # empty lists to store tensors with sequence of images and new tensor with newly calculated target values\n",
    "    mnist_seq = list()\n",
    "    mnist_targets = list()\n",
    "    # for each sequence of images\n",
    "    for seq in mnist_sequence:\n",
    "        # take old target values\n",
    "        target_digits = seq[-1]\n",
    "        # create alternating signes of target values by checking whether the entry index modulo 2 is zero \n",
    "        # (i.e. even entries are positive, uneven ones negative)\n",
    "        alternating_target_numbers = tf.where(tf.math.floormod(range_vals,2)==0, (target_digits), -(target_digits))\n",
    "        # take cum. sum and cast it to float32\n",
    "        new_target = tf.math.cumsum(alternating_target_numbers)\n",
    "        new_target = tf.cast(new_target, tf.float32)\n",
    "        # add sequence to a list and add new target values to a list (later we will create the new dataset out of those)\n",
    "        mnist_seq.append(seq[0])\n",
    "        mnist_targets.append(new_target)\n",
    "            \n",
    "    # create datasets for image sequences and for targets and then zip the two together\n",
    "    sequences_dataset = tf.data.Dataset.from_tensor_slices(mnist_seq)\n",
    "    targets_dataset = tf.data.Dataset.from_tensor_slices(mnist_targets)\n",
    "    mnist_dataset = tf.data.Dataset.zip((sequences_dataset, targets_dataset))\n",
    "    \n",
    "\n",
    "    # cache, batch and prefetch the new dataset\n",
    "    mnist_dataset = mnist_dataset.cache().batch(batch_size).prefetch(10)\n",
    "    \n",
    "    return mnist_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and testing data sets \n",
    "train_dataset = prepare_data(train_ds, 32, 4)\n",
    "test_dataset = prepare_data(test_ds, 32, 4)\n",
    "\n",
    "# print how a batch looks like\n",
    "iterator = iter(train_dataset)\n",
    "iterator.get_next()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 CNN and LSTM Network\n",
    "- first part: basic CNN structure\n",
    "- should extract vector representations from each MNIST image using Conv2D layers as well as (global) pooling or Flatten layers\n",
    "- Conv2D layer can be called on a batch of sequences of images, where the time dimension is in the second axis; time dimension will then be processed like a second batch dimension -> extended batch shape\n",
    "while Conv2D layers accept a (batch, sequence-length, image) data structure with their extended batch size functionality, for the pooling layers to work correctly they need to be wrapped in TensorFlow’s TimeDistributed layers!\n",
    "- Once all images are encoded as vectors, the shape of the tensor should be (batch, sequence-length, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):  \n",
    "        super().__init__()\n",
    "        \n",
    "        # layers\n",
    "        self.conv1 = TimeDistributed(Conv2D(filters=24, kernel_size=3, padding='same', activation='relu'))\n",
    "        self.conv2 = TimeDistributed(Conv2D(filters=24, kernel_size=3, padding='same', activation='relu'))\n",
    "        self.maxpool = TimeDistributed(MaxPooling2D(pool_size=2, strides=2))\n",
    "\n",
    "        self.conv3 = TimeDistributed(Conv2D(filters=48, kernel_size=3, padding='same', activation='relu'))\n",
    "        self.conv4 = TimeDistributed(Conv2D(filters=48, kernel_size=3, padding='same', activation='relu'))\n",
    "        self.globalpool = TimeDistributed(GlobalAvgPool2D())\n",
    "\n",
    "        self.out = TimeDistributed(Dense(10, activation='softmax'))\n",
    "        \n",
    "    @tf.function\n",
    "    def __call__(self, x, training=False):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.globalpool(x)\n",
    "        \n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 LSTM AbstractRNNcell layer\n",
    "- subclass the AbstractRNNCell layer and implement its methods and define the required properties (state size, output size, and get initial state, which determines the initial hidden and cell state of the LSTM (usually tensors filled with zeros))\n",
    "- LSTM-cell layer’s call method should take one (batch of) feature vector(s) as its input, along with the ”states”, a list containing the different state tensors of the LSTM cell (cell state and hidden state!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(tf.keras.layers.AbstractRNNCell):\n",
    "\n",
    "    def __init__(self, trainable=True, name=None, dtype=None, dynamic=False, **kwargs):\n",
    "        super().__init__(trainable, name, dtype, dynamic, **kwargs)\n",
    "\n",
    "        self.hidden_states = 25\n",
    "        self.cell_states = 25\n",
    "        \n",
    "        self.layer1 = Dense(self.hidden_states)\n",
    "        self.layer2 = Dense(self.cell_states)\n",
    "        \n",
    "        # first recurrent layer in the RNN\n",
    "        self.rnn_layer_1 = Dense(self.hidden_states, \n",
    "                                                       kernel_initializer= tf.keras.initializers.Orthogonal(\n",
    "                                                           gain=1.0, seed=None),\n",
    "                                                       activation=tf.nn.sigmoid)\n",
    "        # layer normalization for trainability\n",
    "        self.layer_norm_1 = tf.keras.layers.LayerNormalization()\n",
    "        \n",
    "        # second recurrent layer in the RNN\n",
    "        self.rnn_layer_2 = Dense(self.cell_states, \n",
    "                                                       kernel_initializer= tf.keras.initializers.Orthogonal(\n",
    "                                                           gain=1.0, seed=None), \n",
    "                                                       activation=tf.nn.tanh)\n",
    "        # layer normalization for trainability\n",
    "        self.layer_norm_2 = tf.keras.layers.LayerNormalization()\n",
    "    \n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return [tf.TensorShape([self.hidden_states]), \n",
    "                tf.TensorShape([self.cell_states])]\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return [tf.TensorShape([self.cell_states])]\n",
    "    \n",
    "    def get_initial_state(self, inputs=None, batch_size=None, dtype=None):\n",
    "        return [tf.zeros([self.hidden_states]), \n",
    "                tf.zeros([self.cell_states])]\n",
    "\n",
    "    # call method takes (batch of) feature vector(s) as its input, along with the ”states” \n",
    "    def call(self, inputs, states):\n",
    "        \n",
    "        hidden_state = states[0]\n",
    "        cell_state = states[1]\n",
    "        \n",
    "        # linearly project input\n",
    "        x = self.layer1(inputs) + hidden_state\n",
    "        \n",
    "        # apply first recurrent kernel\n",
    "        new_state_layer_1 = self.rnn_layer_1(x)\n",
    "        \n",
    "        # apply layer norm\n",
    "        x = self.layer_norm_1(new_state_layer_1)\n",
    "        \n",
    "        # linearly project output of layer norm\n",
    "        x = self.layer2(x) + cell_state\n",
    "        \n",
    "        # apply second recurrent layer\n",
    "        new_state_layer_2 = self.rnn_layer_2(x)\n",
    "        \n",
    "        # apply second layer's layer norm\n",
    "        x = self.layer_norm_2(new_state_layer_2)\n",
    "        \n",
    "        # return output and the list of new states of the layers\n",
    "        return x, [new_state_layer_1, new_state_layer_2]\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"hidden_states\": self.hidden_states,\n",
    "                \"cell_states\": self.cell_states}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4 Wrapping LSTM Cell layer with RNN layer\n",
    "- tf.keras.layers.RNN takes an instance of your LSTM cell as the first argument in its constructor\n",
    "- the ”wrapper” RNN layer then takes the sequence of vector representations of the mnist images as its input (batch, seq len, feature dim)\n",
    "- need to specify whether you want the RNN wrapper layer to return the output of your LSTM-cell for every time-step or only for the last step (with the argument return sequences=True) -> generally task-dependent (so think about what makes sense here)\n",
    "- for speed-ups (at the cost of memory usage), set the ”unroll” argument to True\n",
    "# 2.5 Computing model output\n",
    "-could (if the task demands it) use the same Dense layer to predict targets for all time-steps; but likely do not want to have a Dense layer for each time-step’s target prediction (potential for overfitting!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(tf.keras.Model):\n",
    "    def __init__(self, cnn, lstm_cell, optimizer, loss_function):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.cnn = CNN\n",
    "        self.lstm_cell = LSTMCell\n",
    "        self.output_layer = Dense(36,activation='softmax')\n",
    "\n",
    "        self.metrics_list = [\n",
    "            tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
    "            tf.keras.metrics.Mean(name=\"loss\")]\n",
    "\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_function = loss_function\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return self.metrics_list\n",
    "    \n",
    "    def reset_metrics(self):\n",
    "     for metric in self.metrics:\n",
    "        metric.reset_state()\n",
    "    \n",
    "    def call(self, sequence, training = False):\n",
    "        cnn_output = self.cnn(sequence)\n",
    "        cnn_number = tf.argmax(cnn_output, axis=-1)\n",
    "        lstm_output = self.lstm_cell(cnn_output)\n",
    "        output = self.output_layer(lstm_output)\n",
    "        return output\n",
    "    \n",
    "    @tf.function\n",
    "    def training_step(self, image, label):\n",
    "\n",
    "        with tf.GradientTape() as tape: \n",
    "            prediction = self(image, training = True)\n",
    "\n",
    "            loss = self.loss_function(label, prediction)\n",
    "\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients,self.trainable_variables))\n",
    "        self.metrics[0].update_state(label, prediction)\n",
    "        self.metrics[1].update_state(loss)  \n",
    "\n",
    "    @tf.function\n",
    "    def test_step(self, data):\n",
    "        image, label = data\n",
    "        prediction = self(image, training = False)\n",
    "        loss = self.loss_function(label, prediction)\n",
    "        self.metrics[0].update_state(label, prediction)\n",
    "        self.metrics[1].update_state(loss)\n",
    "        return {m.name : m.result() for m in self.metrics}        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.6 Training\n",
    "- own training loop or model.compile and model.fit methods\n",
    "- track experiments properly, save configs (e.g. hyperparameters) of settings, save logs (e.g. with Tensorboard) and checkpoint the model’s weights (or even the complete model)\n",
    "- visualize your results (e.g default history callback of model.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "model = LSTMModel(CNN, LSTMCell, optimizer, loss)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = \"Run_1\"\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logging_callback = tf.keras.callbacks.TensorBoard(log_dir=f\"./logs/{EXPERIMENT_NAME}/{current_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset, validation_data=test_dataset, initial_epoch=0, epochs=5, callbacks=([logging_callback]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the complete model (incl. optimizer state, loss function, metrics etc.)\n",
    "# ideally save to google drive if you're using colab\n",
    "model.save(\"saved_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model and resume training where we had to stop\n",
    "loaded_model = tf.keras.models.load_model(\"saved_model\", custom_objects={\"LSTMCell\": LSTMCell,\n",
    "                                                                         \"LSTMModel\": LSTMModel})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.legend(labels=[\"training\",\"validation\"])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Categorical Crossentropy Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=\"logs/Run_1\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iannwtf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 | packaged by conda-forge | (main, Oct 24 2022, 16:02:16) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b32be4b366388b051e7633bee8b88f892427058db1cb57d13a031e39df811307"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
