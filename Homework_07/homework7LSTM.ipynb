{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Conv2D, AveragePooling2D, TimeDistributed, LSTM, GlobalAvgPool2D, AbstractRNNCell, MaxPooling2D, RNN\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import tqdm\n",
    "\n",
    "# magic line only needed in jupyter notebooks!\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_ds, test_ds) = tfds.load('mnist', split=['train', 'test'], as_supervised=True, with_info=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(mnist, batch_size, sequence_length):\n",
    "    \n",
    "    # change image datatype from unit8 to tf.float32\n",
    "    mnist = mnist.map(lambda img, target:(tf.cast(img, tf.float32), target))\n",
    "    # normalize values\n",
    "    mnist = mnist.map(lambda img, target: (tf.cast(tf.image.per_image_standardization(img), tf.float32), target))\n",
    "    # batch amount of images depending on the wanted sequence length \n",
    "    mnist_sequence =  mnist.shuffle(1000).batch(sequence_length)\n",
    "\n",
    "    # calculations\n",
    "    # create alternating positve and negative signes of target values and take cummulative sum\n",
    "    \n",
    "    # range to identify which target in the sequence needs with new sign\n",
    "    range_vals = tf.range(sequence_length)\n",
    "    # empty lists to store tensors with sequence of images and new tensor with newly calculated target values\n",
    "    mnist_seq = list()\n",
    "    mnist_targets = list()\n",
    "    # for each sequence of images\n",
    "    for seq in mnist_sequence:\n",
    "        # take old target values\n",
    "        target_digits = seq[-1]\n",
    "        # create alternating signes of target values by checking whether the entry index modulo 2 is zero \n",
    "        # (i.e. even entries are positive, uneven ones negative)\n",
    "        alternating_target_numbers = tf.where(tf.math.floormod(range_vals,2)==0, (target_digits), -(target_digits))\n",
    "        # take cum. sum and cast it to float32\n",
    "        new_target = tf.math.cumsum(alternating_target_numbers)\n",
    "        new_target = tf.cast(new_target, tf.float32)\n",
    "        # add sequence to a list and add new target values to a list (later we will create the new dataset out of those)\n",
    "        mnist_seq.append(seq[0])\n",
    "        mnist_targets.append(new_target)\n",
    "            \n",
    "    # create datasets for image sequences and for targets and then zip the two together\n",
    "    sequences_dataset = tf.data.Dataset.from_tensor_slices(mnist_seq)\n",
    "    targets_dataset = tf.data.Dataset.from_tensor_slices(mnist_targets)\n",
    "    mnist_dataset = tf.data.Dataset.zip((sequences_dataset, targets_dataset))\n",
    "    \n",
    "\n",
    "    # cache, batch and prefetch the new dataset\n",
    "    mnist_dataset = mnist_dataset.cache().batch(batch_size).prefetch(10)\n",
    "    \n",
    "    return mnist_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(32, 4, 28, 28, 1), dtype=float32, numpy=\n",
       " array([[[[[-0.30776364],\n",
       "           [-0.30776364],\n",
       "           [-0.30776364],\n",
       "           ...,\n",
       "           [-0.30776364],\n",
       "           [-0.30776364],\n",
       "           [-0.30776364]],\n",
       " \n",
       "          [[-0.30776364],\n",
       "           [-0.30776364],\n",
       "           [-0.30776364],\n",
       "           ...,\n",
       "           [-0.30776364],\n",
       "           [-0.30776364],\n",
       "           [-0.30776364]],\n",
       " \n",
       "          [[-0.30776364],\n",
       "           [-0.30776364],\n",
       "           [-0.30776364],\n",
       "           ...,\n",
       "           [-0.30776364],\n",
       "           [-0.30776364],\n",
       "           [-0.30776364]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.30776364],\n",
       "           [-0.30776364],\n",
       "           [-0.30776364],\n",
       "           ...,\n",
       "           [-0.30776364],\n",
       "           [-0.30776364],\n",
       "           [-0.30776364]],\n",
       " \n",
       "          [[-0.30776364],\n",
       "           [-0.30776364],\n",
       "           [-0.30776364],\n",
       "           ...,\n",
       "           [-0.30776364],\n",
       "           [-0.30776364],\n",
       "           [-0.30776364]],\n",
       " \n",
       "          [[-0.30776364],\n",
       "           [-0.30776364],\n",
       "           [-0.30776364],\n",
       "           ...,\n",
       "           [-0.30776364],\n",
       "           [-0.30776364],\n",
       "           [-0.30776364]]],\n",
       " \n",
       " \n",
       "         [[[-0.5516059 ],\n",
       "           [-0.5516059 ],\n",
       "           [-0.5516059 ],\n",
       "           ...,\n",
       "           [-0.5516059 ],\n",
       "           [-0.5516059 ],\n",
       "           [-0.5516059 ]],\n",
       " \n",
       "          [[-0.5516059 ],\n",
       "           [-0.5516059 ],\n",
       "           [-0.5516059 ],\n",
       "           ...,\n",
       "           [-0.5516059 ],\n",
       "           [-0.5516059 ],\n",
       "           [-0.5516059 ]],\n",
       " \n",
       "          [[-0.5516059 ],\n",
       "           [-0.5516059 ],\n",
       "           [-0.5516059 ],\n",
       "           ...,\n",
       "           [-0.5516059 ],\n",
       "           [-0.5516059 ],\n",
       "           [-0.5516059 ]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.5516059 ],\n",
       "           [-0.5516059 ],\n",
       "           [-0.5516059 ],\n",
       "           ...,\n",
       "           [-0.5516059 ],\n",
       "           [-0.5516059 ],\n",
       "           [-0.5516059 ]],\n",
       " \n",
       "          [[-0.5516059 ],\n",
       "           [-0.5516059 ],\n",
       "           [-0.5516059 ],\n",
       "           ...,\n",
       "           [-0.5516059 ],\n",
       "           [-0.5516059 ],\n",
       "           [-0.5516059 ]],\n",
       " \n",
       "          [[-0.5516059 ],\n",
       "           [-0.5516059 ],\n",
       "           [-0.5516059 ],\n",
       "           ...,\n",
       "           [-0.5516059 ],\n",
       "           [-0.5516059 ],\n",
       "           [-0.5516059 ]]],\n",
       " \n",
       " \n",
       "         [[[-0.4658342 ],\n",
       "           [-0.4658342 ],\n",
       "           [-0.4658342 ],\n",
       "           ...,\n",
       "           [-0.4658342 ],\n",
       "           [-0.4658342 ],\n",
       "           [-0.4658342 ]],\n",
       " \n",
       "          [[-0.4658342 ],\n",
       "           [-0.4658342 ],\n",
       "           [-0.4658342 ],\n",
       "           ...,\n",
       "           [-0.4658342 ],\n",
       "           [-0.4658342 ],\n",
       "           [-0.4658342 ]],\n",
       " \n",
       "          [[-0.4658342 ],\n",
       "           [-0.4658342 ],\n",
       "           [-0.4658342 ],\n",
       "           ...,\n",
       "           [-0.4658342 ],\n",
       "           [-0.4658342 ],\n",
       "           [-0.4658342 ]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.4658342 ],\n",
       "           [-0.4658342 ],\n",
       "           [-0.4658342 ],\n",
       "           ...,\n",
       "           [-0.4658342 ],\n",
       "           [-0.4658342 ],\n",
       "           [-0.4658342 ]],\n",
       " \n",
       "          [[-0.4658342 ],\n",
       "           [-0.4658342 ],\n",
       "           [-0.4658342 ],\n",
       "           ...,\n",
       "           [-0.4658342 ],\n",
       "           [-0.4658342 ],\n",
       "           [-0.4658342 ]],\n",
       " \n",
       "          [[-0.4658342 ],\n",
       "           [-0.4658342 ],\n",
       "           [-0.4658342 ],\n",
       "           ...,\n",
       "           [-0.4658342 ],\n",
       "           [-0.4658342 ],\n",
       "           [-0.4658342 ]]],\n",
       " \n",
       " \n",
       "         [[[-0.47413844],\n",
       "           [-0.47413844],\n",
       "           [-0.47413844],\n",
       "           ...,\n",
       "           [-0.47413844],\n",
       "           [-0.47413844],\n",
       "           [-0.47413844]],\n",
       " \n",
       "          [[-0.47413844],\n",
       "           [-0.47413844],\n",
       "           [-0.47413844],\n",
       "           ...,\n",
       "           [-0.47413844],\n",
       "           [-0.47413844],\n",
       "           [-0.47413844]],\n",
       " \n",
       "          [[-0.47413844],\n",
       "           [-0.47413844],\n",
       "           [-0.47413844],\n",
       "           ...,\n",
       "           [-0.47413844],\n",
       "           [-0.47413844],\n",
       "           [-0.47413844]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.47413844],\n",
       "           [-0.47413844],\n",
       "           [-0.47413844],\n",
       "           ...,\n",
       "           [-0.47413844],\n",
       "           [-0.47413844],\n",
       "           [-0.47413844]],\n",
       " \n",
       "          [[-0.47413844],\n",
       "           [-0.47413844],\n",
       "           [-0.47413844],\n",
       "           ...,\n",
       "           [-0.47413844],\n",
       "           [-0.47413844],\n",
       "           [-0.47413844]],\n",
       " \n",
       "          [[-0.47413844],\n",
       "           [-0.47413844],\n",
       "           [-0.47413844],\n",
       "           ...,\n",
       "           [-0.47413844],\n",
       "           [-0.47413844],\n",
       "           [-0.47413844]]]],\n",
       " \n",
       " \n",
       " \n",
       "        [[[[-0.40045515],\n",
       "           [-0.40045515],\n",
       "           [-0.40045515],\n",
       "           ...,\n",
       "           [-0.40045515],\n",
       "           [-0.40045515],\n",
       "           [-0.40045515]],\n",
       " \n",
       "          [[-0.40045515],\n",
       "           [-0.40045515],\n",
       "           [-0.40045515],\n",
       "           ...,\n",
       "           [-0.40045515],\n",
       "           [-0.40045515],\n",
       "           [-0.40045515]],\n",
       " \n",
       "          [[-0.40045515],\n",
       "           [-0.40045515],\n",
       "           [-0.40045515],\n",
       "           ...,\n",
       "           [-0.40045515],\n",
       "           [-0.40045515],\n",
       "           [-0.40045515]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.40045515],\n",
       "           [-0.40045515],\n",
       "           [-0.40045515],\n",
       "           ...,\n",
       "           [-0.40045515],\n",
       "           [-0.40045515],\n",
       "           [-0.40045515]],\n",
       " \n",
       "          [[-0.40045515],\n",
       "           [-0.40045515],\n",
       "           [-0.40045515],\n",
       "           ...,\n",
       "           [-0.40045515],\n",
       "           [-0.40045515],\n",
       "           [-0.40045515]],\n",
       " \n",
       "          [[-0.40045515],\n",
       "           [-0.40045515],\n",
       "           [-0.40045515],\n",
       "           ...,\n",
       "           [-0.40045515],\n",
       "           [-0.40045515],\n",
       "           [-0.40045515]]],\n",
       " \n",
       " \n",
       "         [[[-0.4542133 ],\n",
       "           [-0.4542133 ],\n",
       "           [-0.4542133 ],\n",
       "           ...,\n",
       "           [-0.4542133 ],\n",
       "           [-0.4542133 ],\n",
       "           [-0.4542133 ]],\n",
       " \n",
       "          [[-0.4542133 ],\n",
       "           [-0.4542133 ],\n",
       "           [-0.4542133 ],\n",
       "           ...,\n",
       "           [-0.4542133 ],\n",
       "           [-0.4542133 ],\n",
       "           [-0.4542133 ]],\n",
       " \n",
       "          [[-0.4542133 ],\n",
       "           [-0.4542133 ],\n",
       "           [-0.4542133 ],\n",
       "           ...,\n",
       "           [-0.4542133 ],\n",
       "           [-0.4542133 ],\n",
       "           [-0.4542133 ]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.4542133 ],\n",
       "           [-0.4542133 ],\n",
       "           [-0.4542133 ],\n",
       "           ...,\n",
       "           [-0.4542133 ],\n",
       "           [-0.4542133 ],\n",
       "           [-0.4542133 ]],\n",
       " \n",
       "          [[-0.4542133 ],\n",
       "           [-0.4542133 ],\n",
       "           [-0.4542133 ],\n",
       "           ...,\n",
       "           [-0.4542133 ],\n",
       "           [-0.4542133 ],\n",
       "           [-0.4542133 ]],\n",
       " \n",
       "          [[-0.4542133 ],\n",
       "           [-0.4542133 ],\n",
       "           [-0.4542133 ],\n",
       "           ...,\n",
       "           [-0.4542133 ],\n",
       "           [-0.4542133 ],\n",
       "           [-0.4542133 ]]],\n",
       " \n",
       " \n",
       "         [[[-0.3190882 ],\n",
       "           [-0.3190882 ],\n",
       "           [-0.3190882 ],\n",
       "           ...,\n",
       "           [-0.3190882 ],\n",
       "           [-0.3190882 ],\n",
       "           [-0.3190882 ]],\n",
       " \n",
       "          [[-0.3190882 ],\n",
       "           [-0.3190882 ],\n",
       "           [-0.3190882 ],\n",
       "           ...,\n",
       "           [-0.3190882 ],\n",
       "           [-0.3190882 ],\n",
       "           [-0.3190882 ]],\n",
       " \n",
       "          [[-0.3190882 ],\n",
       "           [-0.3190882 ],\n",
       "           [-0.3190882 ],\n",
       "           ...,\n",
       "           [-0.3190882 ],\n",
       "           [-0.3190882 ],\n",
       "           [-0.3190882 ]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.3190882 ],\n",
       "           [-0.3190882 ],\n",
       "           [-0.3190882 ],\n",
       "           ...,\n",
       "           [-0.3190882 ],\n",
       "           [-0.3190882 ],\n",
       "           [-0.3190882 ]],\n",
       " \n",
       "          [[-0.3190882 ],\n",
       "           [-0.3190882 ],\n",
       "           [-0.3190882 ],\n",
       "           ...,\n",
       "           [-0.3190882 ],\n",
       "           [-0.3190882 ],\n",
       "           [-0.3190882 ]],\n",
       " \n",
       "          [[-0.3190882 ],\n",
       "           [-0.3190882 ],\n",
       "           [-0.3190882 ],\n",
       "           ...,\n",
       "           [-0.3190882 ],\n",
       "           [-0.3190882 ],\n",
       "           [-0.3190882 ]]],\n",
       " \n",
       " \n",
       "         [[[-0.43649575],\n",
       "           [-0.43649575],\n",
       "           [-0.43649575],\n",
       "           ...,\n",
       "           [-0.43649575],\n",
       "           [-0.43649575],\n",
       "           [-0.43649575]],\n",
       " \n",
       "          [[-0.43649575],\n",
       "           [-0.43649575],\n",
       "           [-0.43649575],\n",
       "           ...,\n",
       "           [-0.43649575],\n",
       "           [-0.43649575],\n",
       "           [-0.43649575]],\n",
       " \n",
       "          [[-0.43649575],\n",
       "           [-0.43649575],\n",
       "           [-0.43649575],\n",
       "           ...,\n",
       "           [-0.43649575],\n",
       "           [-0.43649575],\n",
       "           [-0.43649575]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.43649575],\n",
       "           [-0.43649575],\n",
       "           [-0.43649575],\n",
       "           ...,\n",
       "           [-0.43649575],\n",
       "           [-0.43649575],\n",
       "           [-0.43649575]],\n",
       " \n",
       "          [[-0.43649575],\n",
       "           [-0.43649575],\n",
       "           [-0.43649575],\n",
       "           ...,\n",
       "           [-0.43649575],\n",
       "           [-0.43649575],\n",
       "           [-0.43649575]],\n",
       " \n",
       "          [[-0.43649575],\n",
       "           [-0.43649575],\n",
       "           [-0.43649575],\n",
       "           ...,\n",
       "           [-0.43649575],\n",
       "           [-0.43649575],\n",
       "           [-0.43649575]]]],\n",
       " \n",
       " \n",
       " \n",
       "        [[[[-0.3154014 ],\n",
       "           [-0.3154014 ],\n",
       "           [-0.3154014 ],\n",
       "           ...,\n",
       "           [-0.3154014 ],\n",
       "           [-0.3154014 ],\n",
       "           [-0.3154014 ]],\n",
       " \n",
       "          [[-0.3154014 ],\n",
       "           [-0.3154014 ],\n",
       "           [-0.3154014 ],\n",
       "           ...,\n",
       "           [-0.3154014 ],\n",
       "           [-0.3154014 ],\n",
       "           [-0.3154014 ]],\n",
       " \n",
       "          [[-0.3154014 ],\n",
       "           [-0.3154014 ],\n",
       "           [-0.3154014 ],\n",
       "           ...,\n",
       "           [-0.3154014 ],\n",
       "           [-0.3154014 ],\n",
       "           [-0.3154014 ]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.3154014 ],\n",
       "           [-0.3154014 ],\n",
       "           [-0.3154014 ],\n",
       "           ...,\n",
       "           [-0.3154014 ],\n",
       "           [-0.3154014 ],\n",
       "           [-0.3154014 ]],\n",
       " \n",
       "          [[-0.3154014 ],\n",
       "           [-0.3154014 ],\n",
       "           [-0.3154014 ],\n",
       "           ...,\n",
       "           [-0.3154014 ],\n",
       "           [-0.3154014 ],\n",
       "           [-0.3154014 ]],\n",
       " \n",
       "          [[-0.3154014 ],\n",
       "           [-0.3154014 ],\n",
       "           [-0.3154014 ],\n",
       "           ...,\n",
       "           [-0.3154014 ],\n",
       "           [-0.3154014 ],\n",
       "           [-0.3154014 ]]],\n",
       " \n",
       " \n",
       "         [[[-0.49118072],\n",
       "           [-0.49118072],\n",
       "           [-0.49118072],\n",
       "           ...,\n",
       "           [-0.49118072],\n",
       "           [-0.49118072],\n",
       "           [-0.49118072]],\n",
       " \n",
       "          [[-0.49118072],\n",
       "           [-0.49118072],\n",
       "           [-0.49118072],\n",
       "           ...,\n",
       "           [-0.49118072],\n",
       "           [-0.49118072],\n",
       "           [-0.49118072]],\n",
       " \n",
       "          [[-0.49118072],\n",
       "           [-0.49118072],\n",
       "           [-0.49118072],\n",
       "           ...,\n",
       "           [-0.49118072],\n",
       "           [-0.49118072],\n",
       "           [-0.49118072]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.49118072],\n",
       "           [-0.49118072],\n",
       "           [-0.49118072],\n",
       "           ...,\n",
       "           [-0.49118072],\n",
       "           [-0.49118072],\n",
       "           [-0.49118072]],\n",
       " \n",
       "          [[-0.49118072],\n",
       "           [-0.49118072],\n",
       "           [-0.49118072],\n",
       "           ...,\n",
       "           [-0.49118072],\n",
       "           [-0.49118072],\n",
       "           [-0.49118072]],\n",
       " \n",
       "          [[-0.49118072],\n",
       "           [-0.49118072],\n",
       "           [-0.49118072],\n",
       "           ...,\n",
       "           [-0.49118072],\n",
       "           [-0.49118072],\n",
       "           [-0.49118072]]],\n",
       " \n",
       " \n",
       "         [[[-0.3838402 ],\n",
       "           [-0.3838402 ],\n",
       "           [-0.3838402 ],\n",
       "           ...,\n",
       "           [-0.3838402 ],\n",
       "           [-0.3838402 ],\n",
       "           [-0.3838402 ]],\n",
       " \n",
       "          [[-0.3838402 ],\n",
       "           [-0.3838402 ],\n",
       "           [-0.3838402 ],\n",
       "           ...,\n",
       "           [-0.3838402 ],\n",
       "           [-0.3838402 ],\n",
       "           [-0.3838402 ]],\n",
       " \n",
       "          [[-0.3838402 ],\n",
       "           [-0.3838402 ],\n",
       "           [-0.3838402 ],\n",
       "           ...,\n",
       "           [-0.3838402 ],\n",
       "           [-0.3838402 ],\n",
       "           [-0.3838402 ]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.3838402 ],\n",
       "           [-0.3838402 ],\n",
       "           [-0.3838402 ],\n",
       "           ...,\n",
       "           [-0.3838402 ],\n",
       "           [-0.3838402 ],\n",
       "           [-0.3838402 ]],\n",
       " \n",
       "          [[-0.3838402 ],\n",
       "           [-0.3838402 ],\n",
       "           [-0.3838402 ],\n",
       "           ...,\n",
       "           [-0.3838402 ],\n",
       "           [-0.3838402 ],\n",
       "           [-0.3838402 ]],\n",
       " \n",
       "          [[-0.3838402 ],\n",
       "           [-0.3838402 ],\n",
       "           [-0.3838402 ],\n",
       "           ...,\n",
       "           [-0.3838402 ],\n",
       "           [-0.3838402 ],\n",
       "           [-0.3838402 ]]],\n",
       " \n",
       " \n",
       "         [[[-0.43754655],\n",
       "           [-0.43754655],\n",
       "           [-0.43754655],\n",
       "           ...,\n",
       "           [-0.43754655],\n",
       "           [-0.43754655],\n",
       "           [-0.43754655]],\n",
       " \n",
       "          [[-0.43754655],\n",
       "           [-0.43754655],\n",
       "           [-0.43754655],\n",
       "           ...,\n",
       "           [-0.43754655],\n",
       "           [-0.43754655],\n",
       "           [-0.43754655]],\n",
       " \n",
       "          [[-0.43754655],\n",
       "           [-0.43754655],\n",
       "           [-0.43754655],\n",
       "           ...,\n",
       "           [-0.43754655],\n",
       "           [-0.43754655],\n",
       "           [-0.43754655]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.43754655],\n",
       "           [-0.43754655],\n",
       "           [-0.43754655],\n",
       "           ...,\n",
       "           [-0.43754655],\n",
       "           [-0.43754655],\n",
       "           [-0.43754655]],\n",
       " \n",
       "          [[-0.43754655],\n",
       "           [-0.43754655],\n",
       "           [-0.43754655],\n",
       "           ...,\n",
       "           [-0.43754655],\n",
       "           [-0.43754655],\n",
       "           [-0.43754655]],\n",
       " \n",
       "          [[-0.43754655],\n",
       "           [-0.43754655],\n",
       "           [-0.43754655],\n",
       "           ...,\n",
       "           [-0.43754655],\n",
       "           [-0.43754655],\n",
       "           [-0.43754655]]]],\n",
       " \n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       " \n",
       "        [[[[-0.5038619 ],\n",
       "           [-0.5038619 ],\n",
       "           [-0.5038619 ],\n",
       "           ...,\n",
       "           [-0.5038619 ],\n",
       "           [-0.5038619 ],\n",
       "           [-0.5038619 ]],\n",
       " \n",
       "          [[-0.5038619 ],\n",
       "           [-0.5038619 ],\n",
       "           [-0.5038619 ],\n",
       "           ...,\n",
       "           [-0.5038619 ],\n",
       "           [-0.5038619 ],\n",
       "           [-0.5038619 ]],\n",
       " \n",
       "          [[-0.5038619 ],\n",
       "           [-0.5038619 ],\n",
       "           [-0.5038619 ],\n",
       "           ...,\n",
       "           [-0.5038619 ],\n",
       "           [-0.5038619 ],\n",
       "           [-0.5038619 ]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.5038619 ],\n",
       "           [-0.5038619 ],\n",
       "           [-0.5038619 ],\n",
       "           ...,\n",
       "           [-0.5038619 ],\n",
       "           [-0.5038619 ],\n",
       "           [-0.5038619 ]],\n",
       " \n",
       "          [[-0.5038619 ],\n",
       "           [-0.5038619 ],\n",
       "           [-0.5038619 ],\n",
       "           ...,\n",
       "           [-0.5038619 ],\n",
       "           [-0.5038619 ],\n",
       "           [-0.5038619 ]],\n",
       " \n",
       "          [[-0.5038619 ],\n",
       "           [-0.5038619 ],\n",
       "           [-0.5038619 ],\n",
       "           ...,\n",
       "           [-0.5038619 ],\n",
       "           [-0.5038619 ],\n",
       "           [-0.5038619 ]]],\n",
       " \n",
       " \n",
       "         [[[-0.42946887],\n",
       "           [-0.42946887],\n",
       "           [-0.42946887],\n",
       "           ...,\n",
       "           [-0.42946887],\n",
       "           [-0.42946887],\n",
       "           [-0.42946887]],\n",
       " \n",
       "          [[-0.42946887],\n",
       "           [-0.42946887],\n",
       "           [-0.42946887],\n",
       "           ...,\n",
       "           [-0.42946887],\n",
       "           [-0.42946887],\n",
       "           [-0.42946887]],\n",
       " \n",
       "          [[-0.42946887],\n",
       "           [-0.42946887],\n",
       "           [-0.42946887],\n",
       "           ...,\n",
       "           [-0.42946887],\n",
       "           [-0.42946887],\n",
       "           [-0.42946887]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.42946887],\n",
       "           [-0.42946887],\n",
       "           [-0.42946887],\n",
       "           ...,\n",
       "           [-0.42946887],\n",
       "           [-0.42946887],\n",
       "           [-0.42946887]],\n",
       " \n",
       "          [[-0.42946887],\n",
       "           [-0.42946887],\n",
       "           [-0.42946887],\n",
       "           ...,\n",
       "           [-0.42946887],\n",
       "           [-0.42946887],\n",
       "           [-0.42946887]],\n",
       " \n",
       "          [[-0.42946887],\n",
       "           [-0.42946887],\n",
       "           [-0.42946887],\n",
       "           ...,\n",
       "           [-0.42946887],\n",
       "           [-0.42946887],\n",
       "           [-0.42946887]]],\n",
       " \n",
       " \n",
       "         [[[-0.35909498],\n",
       "           [-0.35909498],\n",
       "           [-0.35909498],\n",
       "           ...,\n",
       "           [-0.35909498],\n",
       "           [-0.35909498],\n",
       "           [-0.35909498]],\n",
       " \n",
       "          [[-0.35909498],\n",
       "           [-0.35909498],\n",
       "           [-0.35909498],\n",
       "           ...,\n",
       "           [-0.35909498],\n",
       "           [-0.35909498],\n",
       "           [-0.35909498]],\n",
       " \n",
       "          [[-0.35909498],\n",
       "           [-0.35909498],\n",
       "           [-0.35909498],\n",
       "           ...,\n",
       "           [-0.35909498],\n",
       "           [-0.35909498],\n",
       "           [-0.35909498]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.35909498],\n",
       "           [-0.35909498],\n",
       "           [-0.35909498],\n",
       "           ...,\n",
       "           [-0.35909498],\n",
       "           [-0.35909498],\n",
       "           [-0.35909498]],\n",
       " \n",
       "          [[-0.35909498],\n",
       "           [-0.35909498],\n",
       "           [-0.35909498],\n",
       "           ...,\n",
       "           [-0.35909498],\n",
       "           [-0.35909498],\n",
       "           [-0.35909498]],\n",
       " \n",
       "          [[-0.35909498],\n",
       "           [-0.35909498],\n",
       "           [-0.35909498],\n",
       "           ...,\n",
       "           [-0.35909498],\n",
       "           [-0.35909498],\n",
       "           [-0.35909498]]],\n",
       " \n",
       " \n",
       "         [[[-0.31148437],\n",
       "           [-0.31148437],\n",
       "           [-0.31148437],\n",
       "           ...,\n",
       "           [-0.31148437],\n",
       "           [-0.31148437],\n",
       "           [-0.31148437]],\n",
       " \n",
       "          [[-0.31148437],\n",
       "           [-0.31148437],\n",
       "           [-0.31148437],\n",
       "           ...,\n",
       "           [-0.31148437],\n",
       "           [-0.31148437],\n",
       "           [-0.31148437]],\n",
       " \n",
       "          [[-0.31148437],\n",
       "           [-0.31148437],\n",
       "           [-0.31148437],\n",
       "           ...,\n",
       "           [-0.31148437],\n",
       "           [-0.31148437],\n",
       "           [-0.31148437]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.31148437],\n",
       "           [-0.31148437],\n",
       "           [-0.31148437],\n",
       "           ...,\n",
       "           [-0.31148437],\n",
       "           [-0.31148437],\n",
       "           [-0.31148437]],\n",
       " \n",
       "          [[-0.31148437],\n",
       "           [-0.31148437],\n",
       "           [-0.31148437],\n",
       "           ...,\n",
       "           [-0.31148437],\n",
       "           [-0.31148437],\n",
       "           [-0.31148437]],\n",
       " \n",
       "          [[-0.31148437],\n",
       "           [-0.31148437],\n",
       "           [-0.31148437],\n",
       "           ...,\n",
       "           [-0.31148437],\n",
       "           [-0.31148437],\n",
       "           [-0.31148437]]]],\n",
       " \n",
       " \n",
       " \n",
       "        [[[[-0.5298657 ],\n",
       "           [-0.5298657 ],\n",
       "           [-0.5298657 ],\n",
       "           ...,\n",
       "           [-0.5298657 ],\n",
       "           [-0.5298657 ],\n",
       "           [-0.5298657 ]],\n",
       " \n",
       "          [[-0.5298657 ],\n",
       "           [-0.5298657 ],\n",
       "           [-0.5298657 ],\n",
       "           ...,\n",
       "           [-0.5298657 ],\n",
       "           [-0.5298657 ],\n",
       "           [-0.5298657 ]],\n",
       " \n",
       "          [[-0.5298657 ],\n",
       "           [-0.5298657 ],\n",
       "           [-0.5298657 ],\n",
       "           ...,\n",
       "           [-0.5298657 ],\n",
       "           [-0.5298657 ],\n",
       "           [-0.5298657 ]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.5298657 ],\n",
       "           [-0.5298657 ],\n",
       "           [-0.5298657 ],\n",
       "           ...,\n",
       "           [-0.5298657 ],\n",
       "           [-0.5298657 ],\n",
       "           [-0.5298657 ]],\n",
       " \n",
       "          [[-0.5298657 ],\n",
       "           [-0.5298657 ],\n",
       "           [-0.5298657 ],\n",
       "           ...,\n",
       "           [-0.5298657 ],\n",
       "           [-0.5298657 ],\n",
       "           [-0.5298657 ]],\n",
       " \n",
       "          [[-0.5298657 ],\n",
       "           [-0.5298657 ],\n",
       "           [-0.5298657 ],\n",
       "           ...,\n",
       "           [-0.5298657 ],\n",
       "           [-0.5298657 ],\n",
       "           [-0.5298657 ]]],\n",
       " \n",
       " \n",
       "         [[[-0.47085306],\n",
       "           [-0.47085306],\n",
       "           [-0.47085306],\n",
       "           ...,\n",
       "           [-0.47085306],\n",
       "           [-0.47085306],\n",
       "           [-0.47085306]],\n",
       " \n",
       "          [[-0.47085306],\n",
       "           [-0.47085306],\n",
       "           [-0.47085306],\n",
       "           ...,\n",
       "           [-0.47085306],\n",
       "           [-0.47085306],\n",
       "           [-0.47085306]],\n",
       " \n",
       "          [[-0.47085306],\n",
       "           [-0.47085306],\n",
       "           [-0.47085306],\n",
       "           ...,\n",
       "           [-0.47085306],\n",
       "           [-0.47085306],\n",
       "           [-0.47085306]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.47085306],\n",
       "           [-0.47085306],\n",
       "           [-0.47085306],\n",
       "           ...,\n",
       "           [-0.47085306],\n",
       "           [-0.47085306],\n",
       "           [-0.47085306]],\n",
       " \n",
       "          [[-0.47085306],\n",
       "           [-0.47085306],\n",
       "           [-0.47085306],\n",
       "           ...,\n",
       "           [-0.47085306],\n",
       "           [-0.47085306],\n",
       "           [-0.47085306]],\n",
       " \n",
       "          [[-0.47085306],\n",
       "           [-0.47085306],\n",
       "           [-0.47085306],\n",
       "           ...,\n",
       "           [-0.47085306],\n",
       "           [-0.47085306],\n",
       "           [-0.47085306]]],\n",
       " \n",
       " \n",
       "         [[[-0.44102487],\n",
       "           [-0.44102487],\n",
       "           [-0.44102487],\n",
       "           ...,\n",
       "           [-0.44102487],\n",
       "           [-0.44102487],\n",
       "           [-0.44102487]],\n",
       " \n",
       "          [[-0.44102487],\n",
       "           [-0.44102487],\n",
       "           [-0.44102487],\n",
       "           ...,\n",
       "           [-0.44102487],\n",
       "           [-0.44102487],\n",
       "           [-0.44102487]],\n",
       " \n",
       "          [[-0.44102487],\n",
       "           [-0.44102487],\n",
       "           [-0.44102487],\n",
       "           ...,\n",
       "           [-0.44102487],\n",
       "           [-0.44102487],\n",
       "           [-0.44102487]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.44102487],\n",
       "           [-0.44102487],\n",
       "           [-0.44102487],\n",
       "           ...,\n",
       "           [-0.44102487],\n",
       "           [-0.44102487],\n",
       "           [-0.44102487]],\n",
       " \n",
       "          [[-0.44102487],\n",
       "           [-0.44102487],\n",
       "           [-0.44102487],\n",
       "           ...,\n",
       "           [-0.44102487],\n",
       "           [-0.44102487],\n",
       "           [-0.44102487]],\n",
       " \n",
       "          [[-0.44102487],\n",
       "           [-0.44102487],\n",
       "           [-0.44102487],\n",
       "           ...,\n",
       "           [-0.44102487],\n",
       "           [-0.44102487],\n",
       "           [-0.44102487]]],\n",
       " \n",
       " \n",
       "         [[[-0.59408194],\n",
       "           [-0.59408194],\n",
       "           [-0.59408194],\n",
       "           ...,\n",
       "           [-0.59408194],\n",
       "           [-0.59408194],\n",
       "           [-0.59408194]],\n",
       " \n",
       "          [[-0.59408194],\n",
       "           [-0.59408194],\n",
       "           [-0.59408194],\n",
       "           ...,\n",
       "           [-0.59408194],\n",
       "           [-0.59408194],\n",
       "           [-0.59408194]],\n",
       " \n",
       "          [[-0.59408194],\n",
       "           [-0.59408194],\n",
       "           [-0.59408194],\n",
       "           ...,\n",
       "           [-0.59408194],\n",
       "           [-0.59408194],\n",
       "           [-0.59408194]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.59408194],\n",
       "           [-0.59408194],\n",
       "           [-0.59408194],\n",
       "           ...,\n",
       "           [-0.59408194],\n",
       "           [-0.59408194],\n",
       "           [-0.59408194]],\n",
       " \n",
       "          [[-0.59408194],\n",
       "           [-0.59408194],\n",
       "           [-0.59408194],\n",
       "           ...,\n",
       "           [-0.59408194],\n",
       "           [-0.59408194],\n",
       "           [-0.59408194]],\n",
       " \n",
       "          [[-0.59408194],\n",
       "           [-0.59408194],\n",
       "           [-0.59408194],\n",
       "           ...,\n",
       "           [-0.59408194],\n",
       "           [-0.59408194],\n",
       "           [-0.59408194]]]],\n",
       " \n",
       " \n",
       " \n",
       "        [[[[-0.27500656],\n",
       "           [-0.27500656],\n",
       "           [-0.27500656],\n",
       "           ...,\n",
       "           [-0.27500656],\n",
       "           [-0.27500656],\n",
       "           [-0.27500656]],\n",
       " \n",
       "          [[-0.27500656],\n",
       "           [-0.27500656],\n",
       "           [-0.27500656],\n",
       "           ...,\n",
       "           [-0.27500656],\n",
       "           [-0.27500656],\n",
       "           [-0.27500656]],\n",
       " \n",
       "          [[-0.27500656],\n",
       "           [-0.27500656],\n",
       "           [-0.27500656],\n",
       "           ...,\n",
       "           [-0.27500656],\n",
       "           [-0.27500656],\n",
       "           [-0.27500656]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.27500656],\n",
       "           [-0.27500656],\n",
       "           [-0.27500656],\n",
       "           ...,\n",
       "           [-0.27500656],\n",
       "           [-0.27500656],\n",
       "           [-0.27500656]],\n",
       " \n",
       "          [[-0.27500656],\n",
       "           [-0.27500656],\n",
       "           [-0.27500656],\n",
       "           ...,\n",
       "           [-0.27500656],\n",
       "           [-0.27500656],\n",
       "           [-0.27500656]],\n",
       " \n",
       "          [[-0.27500656],\n",
       "           [-0.27500656],\n",
       "           [-0.27500656],\n",
       "           ...,\n",
       "           [-0.27500656],\n",
       "           [-0.27500656],\n",
       "           [-0.27500656]]],\n",
       " \n",
       " \n",
       "         [[[-0.44535783],\n",
       "           [-0.44535783],\n",
       "           [-0.44535783],\n",
       "           ...,\n",
       "           [-0.44535783],\n",
       "           [-0.44535783],\n",
       "           [-0.44535783]],\n",
       " \n",
       "          [[-0.44535783],\n",
       "           [-0.44535783],\n",
       "           [-0.44535783],\n",
       "           ...,\n",
       "           [-0.44535783],\n",
       "           [-0.44535783],\n",
       "           [-0.44535783]],\n",
       " \n",
       "          [[-0.44535783],\n",
       "           [-0.44535783],\n",
       "           [-0.44535783],\n",
       "           ...,\n",
       "           [-0.44535783],\n",
       "           [-0.44535783],\n",
       "           [-0.44535783]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.44535783],\n",
       "           [-0.44535783],\n",
       "           [-0.44535783],\n",
       "           ...,\n",
       "           [-0.44535783],\n",
       "           [-0.44535783],\n",
       "           [-0.44535783]],\n",
       " \n",
       "          [[-0.44535783],\n",
       "           [-0.44535783],\n",
       "           [-0.44535783],\n",
       "           ...,\n",
       "           [-0.44535783],\n",
       "           [-0.44535783],\n",
       "           [-0.44535783]],\n",
       " \n",
       "          [[-0.44535783],\n",
       "           [-0.44535783],\n",
       "           [-0.44535783],\n",
       "           ...,\n",
       "           [-0.44535783],\n",
       "           [-0.44535783],\n",
       "           [-0.44535783]]],\n",
       " \n",
       " \n",
       "         [[[-0.46554092],\n",
       "           [-0.46554092],\n",
       "           [-0.46554092],\n",
       "           ...,\n",
       "           [-0.46554092],\n",
       "           [-0.46554092],\n",
       "           [-0.46554092]],\n",
       " \n",
       "          [[-0.46554092],\n",
       "           [-0.46554092],\n",
       "           [-0.46554092],\n",
       "           ...,\n",
       "           [-0.46554092],\n",
       "           [-0.46554092],\n",
       "           [-0.46554092]],\n",
       " \n",
       "          [[-0.46554092],\n",
       "           [-0.46554092],\n",
       "           [-0.46554092],\n",
       "           ...,\n",
       "           [-0.46554092],\n",
       "           [-0.46554092],\n",
       "           [-0.46554092]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.46554092],\n",
       "           [-0.46554092],\n",
       "           [-0.46554092],\n",
       "           ...,\n",
       "           [-0.46554092],\n",
       "           [-0.46554092],\n",
       "           [-0.46554092]],\n",
       " \n",
       "          [[-0.46554092],\n",
       "           [-0.46554092],\n",
       "           [-0.46554092],\n",
       "           ...,\n",
       "           [-0.46554092],\n",
       "           [-0.46554092],\n",
       "           [-0.46554092]],\n",
       " \n",
       "          [[-0.46554092],\n",
       "           [-0.46554092],\n",
       "           [-0.46554092],\n",
       "           ...,\n",
       "           [-0.46554092],\n",
       "           [-0.46554092],\n",
       "           [-0.46554092]]],\n",
       " \n",
       " \n",
       "         [[[-0.30900723],\n",
       "           [-0.30900723],\n",
       "           [-0.30900723],\n",
       "           ...,\n",
       "           [-0.30900723],\n",
       "           [-0.30900723],\n",
       "           [-0.30900723]],\n",
       " \n",
       "          [[-0.30900723],\n",
       "           [-0.30900723],\n",
       "           [-0.30900723],\n",
       "           ...,\n",
       "           [-0.30900723],\n",
       "           [-0.30900723],\n",
       "           [-0.30900723]],\n",
       " \n",
       "          [[-0.30900723],\n",
       "           [-0.30900723],\n",
       "           [-0.30900723],\n",
       "           ...,\n",
       "           [-0.30900723],\n",
       "           [-0.30900723],\n",
       "           [-0.30900723]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.30900723],\n",
       "           [-0.30900723],\n",
       "           [-0.30900723],\n",
       "           ...,\n",
       "           [-0.30900723],\n",
       "           [-0.30900723],\n",
       "           [-0.30900723]],\n",
       " \n",
       "          [[-0.30900723],\n",
       "           [-0.30900723],\n",
       "           [-0.30900723],\n",
       "           ...,\n",
       "           [-0.30900723],\n",
       "           [-0.30900723],\n",
       "           [-0.30900723]],\n",
       " \n",
       "          [[-0.30900723],\n",
       "           [-0.30900723],\n",
       "           [-0.30900723],\n",
       "           ...,\n",
       "           [-0.30900723],\n",
       "           [-0.30900723],\n",
       "           [-0.30900723]]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(32, 4), dtype=float32, numpy=\n",
       " array([[  3.,   3.,   5.,  -3.],\n",
       "        [  7.,   3.,   4.,   4.],\n",
       "        [  5.,  -4.,   4.,   4.],\n",
       "        [  7.,   4.,   6.,   2.],\n",
       "        [  9.,   6.,  15.,  10.],\n",
       "        [  5.,  -3.,  -2.,  -6.],\n",
       "        [  0.,  -1.,   2.,  -4.],\n",
       "        [  2.,   0.,   7.,   4.],\n",
       "        [  7.,   3.,   9.,   0.],\n",
       "        [  4.,  -4.,  -1.,  -1.],\n",
       "        [  5.,   0.,   1.,   1.],\n",
       "        [  1.,  -8.,  -8., -10.],\n",
       "        [  1.,  -5.,   2.,  -6.],\n",
       "        [  7.,  -1.,   5.,   5.],\n",
       "        [  4.,   2.,   7.,   5.],\n",
       "        [  9.,   8.,  11.,   4.],\n",
       "        [  5.,   0.,   3.,  -4.],\n",
       "        [  6.,   1.,   5.,   1.],\n",
       "        [  4.,   1.,   9.,   5.],\n",
       "        [  7.,   6.,   7.,   4.],\n",
       "        [  7.,  -1.,   7.,   2.],\n",
       "        [  6.,   0.,   7.,  -1.],\n",
       "        [  1.,  -1.,   3.,  -6.],\n",
       "        [  5.,   4.,   8.,   4.],\n",
       "        [  3.,  -2.,   4.,  -4.],\n",
       "        [  8.,   2.,   4.,   3.],\n",
       "        [  0.,  -9.,  -8., -15.],\n",
       "        [  0.,   0.,   2.,  -1.],\n",
       "        [  4.,  -1.,  -1., -10.],\n",
       "        [  3.,   1.,   4.,  -3.],\n",
       "        [  8.,   5.,   5.,  -3.],\n",
       "        [  7.,   2.,   7.,   6.]], dtype=float32)>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create training and testing data sets \n",
    "train_dataset = prepare_data(train_ds, 32, 4)\n",
    "test_dataset = prepare_data(test_ds, 32, 4)\n",
    "\n",
    "# print how a batch looks like\n",
    "iterator = iter(train_dataset)\n",
    "iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' from tensorflow.python.ops.numpy_ops import np_config; np_config.enable_numpy_behavior()\\n# Get a batch of data from the dataset\\nbatch_data = next(iter(test_dataset))\\n\\n# Extract the features and labels from the batch\\nfeatures, labels = batch_data\\n\\n# Convert the features to a Tensor object\\nfeatures = tf.convert_to_tensor(features.numpy())\\n\\n# Reshape the features to the correct shape (batch_size, sequence_length, feature_dimension)\\nfeatures = features.reshape(32, 4, 1)\\n\\n# Call the model on the reshaped features '"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" from tensorflow.python.ops.numpy_ops import np_config; np_config.enable_numpy_behavior()\n",
    "# Get a batch of data from the dataset\n",
    "batch_data = next(iter(test_dataset))\n",
    "\n",
    "# Extract the features and labels from the batch\n",
    "features, labels = batch_data\n",
    "\n",
    "# Convert the features to a Tensor object\n",
    "features = tf.convert_to_tensor(features.numpy())\n",
    "\n",
    "# Reshape the features to the correct shape (batch_size, sequence_length, feature_dimension)\n",
    "features = features.reshape(32, 4, 1)\n",
    "\n",
    "# Call the model on the reshaped features \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):  \n",
    "        super().__init__()\n",
    "        \n",
    "        # layers\n",
    "        self.conv1 = TimeDistributed(Conv2D(filters=24, kernel_size=3, padding='same', activation='relu'))\n",
    "        self.conv2 = TimeDistributed(Conv2D(filters=24, kernel_size=3, padding='same', activation='relu'))\n",
    "        self.maxpool = TimeDistributed(MaxPooling2D(pool_size=2, strides=2))\n",
    "\n",
    "        self.conv3 = TimeDistributed(Conv2D(filters=48, kernel_size=3, padding='same', activation='relu'))\n",
    "        self.conv4 = TimeDistributed(Conv2D(filters=48, kernel_size=3, padding='same', activation='relu'))\n",
    "        self.globalpool = TimeDistributed(GlobalAvgPool2D())\n",
    "\n",
    "        self.out = TimeDistributed(Dense(10, activation='softmax'))\n",
    "        \n",
    "    @tf.function\n",
    "    def __call__(self, x, training=False):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.globalpool(x)\n",
    "        \n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(tf.keras.layers.AbstractRNNCell):\n",
    "\n",
    "    def __init__(self, trainable=True, name=None, dtype=None, dynamic=False, **kwargs):\n",
    "        super().__init__(trainable, name, dtype, dynamic, **kwargs)\n",
    "\n",
    "        self.hidden_states = 25\n",
    "        self.cell_states = 25\n",
    "        \n",
    "        self.layer1 = Dense(self.hidden_states)\n",
    "        self.layer2 = Dense(self.cell_states)\n",
    "        \n",
    "        # first recurrent layer in the RNN\n",
    "        self.rnn_layer_1 = Dense(self.hidden_states, \n",
    "                                                       kernel_initializer= tf.keras.initializers.Orthogonal(\n",
    "                                                           gain=1.0, seed=None),\n",
    "                                                       activation=tf.nn.sigmoid)\n",
    "        # layer normalization for trainability\n",
    "        self.layer_norm_1 = tf.keras.layers.LayerNormalization()\n",
    "        \n",
    "        # second recurrent layer in the RNN\n",
    "        self.rnn_layer_2 = Dense(self.cell_states, \n",
    "                                                       kernel_initializer= tf.keras.initializers.Orthogonal(\n",
    "                                                           gain=1.0, seed=None), \n",
    "                                                       activation=tf.nn.tanh)\n",
    "        # layer normalization for trainability\n",
    "        self.layer_norm_2 = tf.keras.layers.LayerNormalization()\n",
    "    \n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return [tf.TensorShape([self.hidden_states]), \n",
    "                tf.TensorShape([self.cell_states])]\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return [tf.TensorShape([self.cell_states])]\n",
    "    \n",
    "    def get_initial_state(self, inputs=None, batch_size=None, dtype=None):\n",
    "        return [tf.zeros([self.hidden_states]), \n",
    "                tf.zeros([self.cell_states])]\n",
    "\n",
    "    # call method takes (batch of) feature vector(s) as its input, along with the ”states” \n",
    "    def call(self, inputs, states):\n",
    "        \n",
    "        hidden_state = states[0]\n",
    "        cell_state = states[1]\n",
    "        \n",
    "        # linearly project input\n",
    "        x = self.layer1(inputs) + hidden_state\n",
    "        \n",
    "        # apply first recurrent kernel\n",
    "        new_state_layer_1 = self.rnn_layer_1(x)\n",
    "        \n",
    "        # apply layer norm\n",
    "        x = self.layer_norm_1(new_state_layer_1)\n",
    "        \n",
    "        # linearly project output of layer norm\n",
    "        x = self.layer2(x) + cell_state\n",
    "        \n",
    "        # apply second recurrent layer\n",
    "        new_state_layer_2 = self.rnn_layer_2(x)\n",
    "        \n",
    "        # apply second layer's layer norm\n",
    "        x = self.layer_norm_2(new_state_layer_2)\n",
    "        \n",
    "        # return output and the list of new states of the layers\n",
    "        return x, [new_state_layer_1, new_state_layer_2]\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"hidden_states\": self.hidden_states,\n",
    "                \"cell_states\": self.cell_states}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(tf.keras.Model):\n",
    "    def __init__(self, cnn, lstm_cell, optimizer, loss_function):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.cnn = CNN\n",
    "        self.lstm_cell = LSTMCell\n",
    "        self.output_layer = Dense(36,activation='softmax')\n",
    "\n",
    "        self.metrics_list = [\n",
    "            tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
    "            tf.keras.metrics.Mean(name=\"loss\")]\n",
    "\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_function = loss_function\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return self.metrics_list\n",
    "    \n",
    "    def reset_metrics(self):\n",
    "     for metric in self.metrics:\n",
    "        metric.reset_state()\n",
    "    \n",
    "    def call(self, sequence, training = False):\n",
    "        cnn_output = self.cnn(sequence)\n",
    "        cnn_number = tf.argmax(cnn_output, axis=-1)\n",
    "        lstm_output = self.lstm_cell(cnn_output)\n",
    "        output = self.output_layer(lstm_output)\n",
    "        return output\n",
    "    \n",
    "    @tf.function\n",
    "    def training_step(self, image, label):\n",
    "\n",
    "        with tf.GradientTape() as tape: \n",
    "            prediction = self(image, training = True)\n",
    "\n",
    "            loss = self.loss_function(label, prediction)\n",
    "\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients,self.trainable_variables))\n",
    "        self.metrics[0].update_state(label, prediction)\n",
    "        self.metrics[1].update_state(loss)  \n",
    "\n",
    "    @tf.function\n",
    "    def test_step(self, data):\n",
    "        image, label = data\n",
    "        prediction = self(image, training = False)\n",
    "        loss = self.loss_function(label, prediction)\n",
    "        self.metrics[0].update_state(label, prediction)\n",
    "        self.metrics[1].update_state(loss)\n",
    "        return {m.name : m.result() for m in self.metrics}        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=le-3)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = \"Run_1\"\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logging_callback = tf.keras.callbacks.TensorBoard(log_dir=f\"./logs/{EXPERIMENT_NAME}/{current_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset, validation_data=test_dataset, initial_epoch=0, epochs=5, callbacks=([logging_callback]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the complete model (incl. optimizer state, loss function, metrics etc.)\n",
    "# ideally save to google drive if you're using colab\n",
    "model.save(\"saved_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model and resume training where we had to stop\n",
    "loaded_model = tf.keras.models.load_model(\"saved_model\", custom_objects={\"LSTMCell\": LSTMCell,\n",
    "                                                                         \"LSTMModel\": LSTMModel})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.legend(labels=[\"training\",\"validation\"])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Categorical Crossentropy Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=\"logs/Run_1\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iannwtf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b32be4b366388b051e7633bee8b88f892427058db1cb57d13a031e39df811307"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
