{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 07\n",
    "\n",
    "## Assignment 2: Implement LSTM\n",
    "\n",
    "### 2.1 Prepare dataset\n",
    "\n",
    "- MNIST\n",
    "- divide the images up into sequences that will be fed into the model; shape should be (batch, sequencelength, features)\n",
    "- need to alternate the signs of the targets, and implement a cumulative sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Conv2D, AveragePooling2D, TimeDistributed, LSTM, GlobalAvgPool2D, AbstractRNNCell, MaxPooling2D, RNN\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import tqdm\n",
    "\n",
    "# magic line only needed in jupyter notebooks!\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_ds, test_ds) = tfds.load('mnist', split=['train', 'test'], as_supervised=True, with_info=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(mnist, batch_size, sequence_length):\n",
    "    \n",
    "    # change image datatype from unit8 to tf.float32\n",
    "    mnist = mnist.map(lambda img, target:(tf.cast(img, tf.float32), target))\n",
    "    # normalize values\n",
    "    mnist = mnist.map(lambda img, target: (tf.cast(tf.image.per_image_standardization(img), tf.float32), target))\n",
    "    # batch amount of images depending on the wanted sequence length \n",
    "    mnist_sequence =  mnist.shuffle(1000).batch(sequence_length)\n",
    "\n",
    "    # calculations\n",
    "    # create alternating positve and negative signes of target values and take cummulative sum\n",
    "    \n",
    "    # range to identify which target in the sequence needs with new sign\n",
    "    range_vals = tf.range(sequence_length)\n",
    "    # empty lists to store tensors with sequence of images and new tensor with newly calculated target values\n",
    "    mnist_seq = list()\n",
    "    mnist_targets = list()\n",
    "    # for each sequence of images\n",
    "    for seq in mnist_sequence:\n",
    "        # take old target values\n",
    "        target_digits = seq[-1]\n",
    "        # create alternating signes of target values by checking whether the entry index modulo 2 is zero \n",
    "        # (i.e. even entries are positive, uneven ones negative)\n",
    "        alternating_target_numbers = tf.where(tf.math.floormod(range_vals,2)==0, (target_digits), -(target_digits))\n",
    "        # take cum. sum and cast it to float32\n",
    "        new_target = tf.math.cumsum(alternating_target_numbers)\n",
    "        new_target = tf.cast(new_target, tf.float32)\n",
    "        # add sequence to a list and add new target values to a list (later we will create the new dataset out of those)\n",
    "        mnist_seq.append(seq[0])\n",
    "        mnist_targets.append(new_target)\n",
    "            \n",
    "    # create datasets for image sequences and for targets and then zip the two together\n",
    "    sequences_dataset = tf.data.Dataset.from_tensor_slices(mnist_seq)\n",
    "    targets_dataset = tf.data.Dataset.from_tensor_slices(mnist_targets)\n",
    "    mnist_dataset = tf.data.Dataset.zip((sequences_dataset, targets_dataset))\n",
    "    \n",
    "\n",
    "    # cache, batch and prefetch the new dataset\n",
    "    mnist_dataset = mnist_dataset.cache().batch(batch_size).prefetch(10)\n",
    "    \n",
    "    return mnist_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(32, 4, 28, 28, 1), dtype=float32, numpy=\n",
       " array([[[[[-0.2391585 ],\n",
       "           [-0.2391585 ],\n",
       "           [-0.2391585 ],\n",
       "           ...,\n",
       "           [-0.2391585 ],\n",
       "           [-0.2391585 ],\n",
       "           [-0.2391585 ]],\n",
       " \n",
       "          [[-0.2391585 ],\n",
       "           [-0.2391585 ],\n",
       "           [-0.2391585 ],\n",
       "           ...,\n",
       "           [-0.2391585 ],\n",
       "           [-0.2391585 ],\n",
       "           [-0.2391585 ]],\n",
       " \n",
       "          [[-0.2391585 ],\n",
       "           [-0.2391585 ],\n",
       "           [-0.2391585 ],\n",
       "           ...,\n",
       "           [-0.2391585 ],\n",
       "           [-0.2391585 ],\n",
       "           [-0.2391585 ]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.2391585 ],\n",
       "           [-0.2391585 ],\n",
       "           [-0.2391585 ],\n",
       "           ...,\n",
       "           [-0.2391585 ],\n",
       "           [-0.2391585 ],\n",
       "           [-0.2391585 ]],\n",
       " \n",
       "          [[-0.2391585 ],\n",
       "           [-0.2391585 ],\n",
       "           [-0.2391585 ],\n",
       "           ...,\n",
       "           [-0.2391585 ],\n",
       "           [-0.2391585 ],\n",
       "           [-0.2391585 ]],\n",
       " \n",
       "          [[-0.2391585 ],\n",
       "           [-0.2391585 ],\n",
       "           [-0.2391585 ],\n",
       "           ...,\n",
       "           [-0.2391585 ],\n",
       "           [-0.2391585 ],\n",
       "           [-0.2391585 ]]],\n",
       " \n",
       " \n",
       "         [[[-0.3053386 ],\n",
       "           [-0.3053386 ],\n",
       "           [-0.3053386 ],\n",
       "           ...,\n",
       "           [-0.3053386 ],\n",
       "           [-0.3053386 ],\n",
       "           [-0.3053386 ]],\n",
       " \n",
       "          [[-0.3053386 ],\n",
       "           [-0.3053386 ],\n",
       "           [-0.3053386 ],\n",
       "           ...,\n",
       "           [-0.3053386 ],\n",
       "           [-0.3053386 ],\n",
       "           [-0.3053386 ]],\n",
       " \n",
       "          [[-0.3053386 ],\n",
       "           [-0.3053386 ],\n",
       "           [-0.3053386 ],\n",
       "           ...,\n",
       "           [-0.3053386 ],\n",
       "           [-0.3053386 ],\n",
       "           [-0.3053386 ]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.3053386 ],\n",
       "           [-0.3053386 ],\n",
       "           [-0.3053386 ],\n",
       "           ...,\n",
       "           [-0.3053386 ],\n",
       "           [-0.3053386 ],\n",
       "           [-0.3053386 ]],\n",
       " \n",
       "          [[-0.3053386 ],\n",
       "           [-0.3053386 ],\n",
       "           [-0.3053386 ],\n",
       "           ...,\n",
       "           [-0.3053386 ],\n",
       "           [-0.3053386 ],\n",
       "           [-0.3053386 ]],\n",
       " \n",
       "          [[-0.3053386 ],\n",
       "           [-0.3053386 ],\n",
       "           [-0.3053386 ],\n",
       "           ...,\n",
       "           [-0.3053386 ],\n",
       "           [-0.3053386 ],\n",
       "           [-0.3053386 ]]],\n",
       " \n",
       " \n",
       "         [[[-0.21695907],\n",
       "           [-0.21695907],\n",
       "           [-0.21695907],\n",
       "           ...,\n",
       "           [-0.21695907],\n",
       "           [-0.21695907],\n",
       "           [-0.21695907]],\n",
       " \n",
       "          [[-0.21695907],\n",
       "           [-0.21695907],\n",
       "           [-0.21695907],\n",
       "           ...,\n",
       "           [-0.21695907],\n",
       "           [-0.21695907],\n",
       "           [-0.21695907]],\n",
       " \n",
       "          [[-0.21695907],\n",
       "           [-0.21695907],\n",
       "           [-0.21695907],\n",
       "           ...,\n",
       "           [-0.21695907],\n",
       "           [-0.21695907],\n",
       "           [-0.21695907]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.21695907],\n",
       "           [-0.21695907],\n",
       "           [-0.21695907],\n",
       "           ...,\n",
       "           [-0.21695907],\n",
       "           [-0.21695907],\n",
       "           [-0.21695907]],\n",
       " \n",
       "          [[-0.21695907],\n",
       "           [-0.21695907],\n",
       "           [-0.21695907],\n",
       "           ...,\n",
       "           [-0.21695907],\n",
       "           [-0.21695907],\n",
       "           [-0.21695907]],\n",
       " \n",
       "          [[-0.21695907],\n",
       "           [-0.21695907],\n",
       "           [-0.21695907],\n",
       "           ...,\n",
       "           [-0.21695907],\n",
       "           [-0.21695907],\n",
       "           [-0.21695907]]],\n",
       " \n",
       " \n",
       "         [[[-0.37633246],\n",
       "           [-0.37633246],\n",
       "           [-0.37633246],\n",
       "           ...,\n",
       "           [-0.37633246],\n",
       "           [-0.37633246],\n",
       "           [-0.37633246]],\n",
       " \n",
       "          [[-0.37633246],\n",
       "           [-0.37633246],\n",
       "           [-0.37633246],\n",
       "           ...,\n",
       "           [-0.37633246],\n",
       "           [-0.37633246],\n",
       "           [-0.37633246]],\n",
       " \n",
       "          [[-0.37633246],\n",
       "           [-0.37633246],\n",
       "           [-0.37633246],\n",
       "           ...,\n",
       "           [-0.37633246],\n",
       "           [-0.37633246],\n",
       "           [-0.37633246]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.37633246],\n",
       "           [-0.37633246],\n",
       "           [-0.37633246],\n",
       "           ...,\n",
       "           [-0.37633246],\n",
       "           [-0.37633246],\n",
       "           [-0.37633246]],\n",
       " \n",
       "          [[-0.37633246],\n",
       "           [-0.37633246],\n",
       "           [-0.37633246],\n",
       "           ...,\n",
       "           [-0.37633246],\n",
       "           [-0.37633246],\n",
       "           [-0.37633246]],\n",
       " \n",
       "          [[-0.37633246],\n",
       "           [-0.37633246],\n",
       "           [-0.37633246],\n",
       "           ...,\n",
       "           [-0.37633246],\n",
       "           [-0.37633246],\n",
       "           [-0.37633246]]]],\n",
       " \n",
       " \n",
       " \n",
       "        [[[[-0.4576426 ],\n",
       "           [-0.4576426 ],\n",
       "           [-0.4576426 ],\n",
       "           ...,\n",
       "           [-0.4576426 ],\n",
       "           [-0.4576426 ],\n",
       "           [-0.4576426 ]],\n",
       " \n",
       "          [[-0.4576426 ],\n",
       "           [-0.4576426 ],\n",
       "           [-0.4576426 ],\n",
       "           ...,\n",
       "           [-0.4576426 ],\n",
       "           [-0.4576426 ],\n",
       "           [-0.4576426 ]],\n",
       " \n",
       "          [[-0.4576426 ],\n",
       "           [-0.4576426 ],\n",
       "           [-0.4576426 ],\n",
       "           ...,\n",
       "           [-0.4576426 ],\n",
       "           [-0.4576426 ],\n",
       "           [-0.4576426 ]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.4576426 ],\n",
       "           [-0.4576426 ],\n",
       "           [-0.4576426 ],\n",
       "           ...,\n",
       "           [-0.4576426 ],\n",
       "           [-0.4576426 ],\n",
       "           [-0.4576426 ]],\n",
       " \n",
       "          [[-0.4576426 ],\n",
       "           [-0.4576426 ],\n",
       "           [-0.4576426 ],\n",
       "           ...,\n",
       "           [-0.4576426 ],\n",
       "           [-0.4576426 ],\n",
       "           [-0.4576426 ]],\n",
       " \n",
       "          [[-0.4576426 ],\n",
       "           [-0.4576426 ],\n",
       "           [-0.4576426 ],\n",
       "           ...,\n",
       "           [-0.4576426 ],\n",
       "           [-0.4576426 ],\n",
       "           [-0.4576426 ]]],\n",
       " \n",
       " \n",
       "         [[[-0.420814  ],\n",
       "           [-0.420814  ],\n",
       "           [-0.420814  ],\n",
       "           ...,\n",
       "           [-0.420814  ],\n",
       "           [-0.420814  ],\n",
       "           [-0.420814  ]],\n",
       " \n",
       "          [[-0.420814  ],\n",
       "           [-0.420814  ],\n",
       "           [-0.420814  ],\n",
       "           ...,\n",
       "           [-0.420814  ],\n",
       "           [-0.420814  ],\n",
       "           [-0.420814  ]],\n",
       " \n",
       "          [[-0.420814  ],\n",
       "           [-0.420814  ],\n",
       "           [-0.420814  ],\n",
       "           ...,\n",
       "           [-0.420814  ],\n",
       "           [-0.420814  ],\n",
       "           [-0.420814  ]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.420814  ],\n",
       "           [-0.420814  ],\n",
       "           [-0.420814  ],\n",
       "           ...,\n",
       "           [-0.420814  ],\n",
       "           [-0.420814  ],\n",
       "           [-0.420814  ]],\n",
       " \n",
       "          [[-0.420814  ],\n",
       "           [-0.420814  ],\n",
       "           [-0.420814  ],\n",
       "           ...,\n",
       "           [-0.420814  ],\n",
       "           [-0.420814  ],\n",
       "           [-0.420814  ]],\n",
       " \n",
       "          [[-0.420814  ],\n",
       "           [-0.420814  ],\n",
       "           [-0.420814  ],\n",
       "           ...,\n",
       "           [-0.420814  ],\n",
       "           [-0.420814  ],\n",
       "           [-0.420814  ]]],\n",
       " \n",
       " \n",
       "         [[[-0.453657  ],\n",
       "           [-0.453657  ],\n",
       "           [-0.453657  ],\n",
       "           ...,\n",
       "           [-0.453657  ],\n",
       "           [-0.453657  ],\n",
       "           [-0.453657  ]],\n",
       " \n",
       "          [[-0.453657  ],\n",
       "           [-0.453657  ],\n",
       "           [-0.453657  ],\n",
       "           ...,\n",
       "           [-0.453657  ],\n",
       "           [-0.453657  ],\n",
       "           [-0.453657  ]],\n",
       " \n",
       "          [[-0.453657  ],\n",
       "           [-0.453657  ],\n",
       "           [-0.453657  ],\n",
       "           ...,\n",
       "           [-0.453657  ],\n",
       "           [-0.453657  ],\n",
       "           [-0.453657  ]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.453657  ],\n",
       "           [-0.453657  ],\n",
       "           [-0.453657  ],\n",
       "           ...,\n",
       "           [-0.453657  ],\n",
       "           [-0.453657  ],\n",
       "           [-0.453657  ]],\n",
       " \n",
       "          [[-0.453657  ],\n",
       "           [-0.453657  ],\n",
       "           [-0.453657  ],\n",
       "           ...,\n",
       "           [-0.453657  ],\n",
       "           [-0.453657  ],\n",
       "           [-0.453657  ]],\n",
       " \n",
       "          [[-0.453657  ],\n",
       "           [-0.453657  ],\n",
       "           [-0.453657  ],\n",
       "           ...,\n",
       "           [-0.453657  ],\n",
       "           [-0.453657  ],\n",
       "           [-0.453657  ]]],\n",
       " \n",
       " \n",
       "         [[[-0.37659478],\n",
       "           [-0.37659478],\n",
       "           [-0.37659478],\n",
       "           ...,\n",
       "           [-0.37659478],\n",
       "           [-0.37659478],\n",
       "           [-0.37659478]],\n",
       " \n",
       "          [[-0.37659478],\n",
       "           [-0.37659478],\n",
       "           [-0.37659478],\n",
       "           ...,\n",
       "           [-0.37659478],\n",
       "           [-0.37659478],\n",
       "           [-0.37659478]],\n",
       " \n",
       "          [[-0.37659478],\n",
       "           [-0.37659478],\n",
       "           [-0.37659478],\n",
       "           ...,\n",
       "           [-0.37659478],\n",
       "           [-0.37659478],\n",
       "           [-0.37659478]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.37659478],\n",
       "           [-0.37659478],\n",
       "           [-0.37659478],\n",
       "           ...,\n",
       "           [-0.37659478],\n",
       "           [-0.37659478],\n",
       "           [-0.37659478]],\n",
       " \n",
       "          [[-0.37659478],\n",
       "           [-0.37659478],\n",
       "           [-0.37659478],\n",
       "           ...,\n",
       "           [-0.37659478],\n",
       "           [-0.37659478],\n",
       "           [-0.37659478]],\n",
       " \n",
       "          [[-0.37659478],\n",
       "           [-0.37659478],\n",
       "           [-0.37659478],\n",
       "           ...,\n",
       "           [-0.37659478],\n",
       "           [-0.37659478],\n",
       "           [-0.37659478]]]],\n",
       " \n",
       " \n",
       " \n",
       "        [[[[-0.2927224 ],\n",
       "           [-0.2927224 ],\n",
       "           [-0.2927224 ],\n",
       "           ...,\n",
       "           [-0.2927224 ],\n",
       "           [-0.2927224 ],\n",
       "           [-0.2927224 ]],\n",
       " \n",
       "          [[-0.2927224 ],\n",
       "           [-0.2927224 ],\n",
       "           [-0.2927224 ],\n",
       "           ...,\n",
       "           [-0.2927224 ],\n",
       "           [-0.2927224 ],\n",
       "           [-0.2927224 ]],\n",
       " \n",
       "          [[-0.2927224 ],\n",
       "           [-0.2927224 ],\n",
       "           [-0.2927224 ],\n",
       "           ...,\n",
       "           [-0.2927224 ],\n",
       "           [-0.2927224 ],\n",
       "           [-0.2927224 ]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.2927224 ],\n",
       "           [-0.2927224 ],\n",
       "           [-0.2927224 ],\n",
       "           ...,\n",
       "           [-0.2927224 ],\n",
       "           [-0.2927224 ],\n",
       "           [-0.2927224 ]],\n",
       " \n",
       "          [[-0.2927224 ],\n",
       "           [-0.2927224 ],\n",
       "           [-0.2927224 ],\n",
       "           ...,\n",
       "           [-0.2927224 ],\n",
       "           [-0.2927224 ],\n",
       "           [-0.2927224 ]],\n",
       " \n",
       "          [[-0.2927224 ],\n",
       "           [-0.2927224 ],\n",
       "           [-0.2927224 ],\n",
       "           ...,\n",
       "           [-0.2927224 ],\n",
       "           [-0.2927224 ],\n",
       "           [-0.2927224 ]]],\n",
       " \n",
       " \n",
       "         [[[-0.45127925],\n",
       "           [-0.45127925],\n",
       "           [-0.45127925],\n",
       "           ...,\n",
       "           [-0.45127925],\n",
       "           [-0.45127925],\n",
       "           [-0.45127925]],\n",
       " \n",
       "          [[-0.45127925],\n",
       "           [-0.45127925],\n",
       "           [-0.45127925],\n",
       "           ...,\n",
       "           [-0.45127925],\n",
       "           [-0.45127925],\n",
       "           [-0.45127925]],\n",
       " \n",
       "          [[-0.45127925],\n",
       "           [-0.45127925],\n",
       "           [-0.45127925],\n",
       "           ...,\n",
       "           [-0.45127925],\n",
       "           [-0.45127925],\n",
       "           [-0.45127925]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.45127925],\n",
       "           [-0.45127925],\n",
       "           [-0.45127925],\n",
       "           ...,\n",
       "           [-0.45127925],\n",
       "           [-0.45127925],\n",
       "           [-0.45127925]],\n",
       " \n",
       "          [[-0.45127925],\n",
       "           [-0.45127925],\n",
       "           [-0.45127925],\n",
       "           ...,\n",
       "           [-0.45127925],\n",
       "           [-0.45127925],\n",
       "           [-0.45127925]],\n",
       " \n",
       "          [[-0.45127925],\n",
       "           [-0.45127925],\n",
       "           [-0.45127925],\n",
       "           ...,\n",
       "           [-0.45127925],\n",
       "           [-0.45127925],\n",
       "           [-0.45127925]]],\n",
       " \n",
       " \n",
       "         [[[-0.48283142],\n",
       "           [-0.48283142],\n",
       "           [-0.48283142],\n",
       "           ...,\n",
       "           [-0.48283142],\n",
       "           [-0.48283142],\n",
       "           [-0.48283142]],\n",
       " \n",
       "          [[-0.48283142],\n",
       "           [-0.48283142],\n",
       "           [-0.48283142],\n",
       "           ...,\n",
       "           [-0.48283142],\n",
       "           [-0.48283142],\n",
       "           [-0.48283142]],\n",
       " \n",
       "          [[-0.48283142],\n",
       "           [-0.48283142],\n",
       "           [-0.48283142],\n",
       "           ...,\n",
       "           [-0.48283142],\n",
       "           [-0.48283142],\n",
       "           [-0.48283142]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.48283142],\n",
       "           [-0.48283142],\n",
       "           [-0.48283142],\n",
       "           ...,\n",
       "           [-0.48283142],\n",
       "           [-0.48283142],\n",
       "           [-0.48283142]],\n",
       " \n",
       "          [[-0.48283142],\n",
       "           [-0.48283142],\n",
       "           [-0.48283142],\n",
       "           ...,\n",
       "           [-0.48283142],\n",
       "           [-0.48283142],\n",
       "           [-0.48283142]],\n",
       " \n",
       "          [[-0.48283142],\n",
       "           [-0.48283142],\n",
       "           [-0.48283142],\n",
       "           ...,\n",
       "           [-0.48283142],\n",
       "           [-0.48283142],\n",
       "           [-0.48283142]]],\n",
       " \n",
       " \n",
       "         [[[-0.45534137],\n",
       "           [-0.45534137],\n",
       "           [-0.45534137],\n",
       "           ...,\n",
       "           [-0.45534137],\n",
       "           [-0.45534137],\n",
       "           [-0.45534137]],\n",
       " \n",
       "          [[-0.45534137],\n",
       "           [-0.45534137],\n",
       "           [-0.45534137],\n",
       "           ...,\n",
       "           [-0.45534137],\n",
       "           [-0.45534137],\n",
       "           [-0.45534137]],\n",
       " \n",
       "          [[-0.45534137],\n",
       "           [-0.45534137],\n",
       "           [-0.45534137],\n",
       "           ...,\n",
       "           [-0.45534137],\n",
       "           [-0.45534137],\n",
       "           [-0.45534137]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.45534137],\n",
       "           [-0.45534137],\n",
       "           [-0.45534137],\n",
       "           ...,\n",
       "           [-0.45534137],\n",
       "           [-0.45534137],\n",
       "           [-0.45534137]],\n",
       " \n",
       "          [[-0.45534137],\n",
       "           [-0.45534137],\n",
       "           [-0.45534137],\n",
       "           ...,\n",
       "           [-0.45534137],\n",
       "           [-0.45534137],\n",
       "           [-0.45534137]],\n",
       " \n",
       "          [[-0.45534137],\n",
       "           [-0.45534137],\n",
       "           [-0.45534137],\n",
       "           ...,\n",
       "           [-0.45534137],\n",
       "           [-0.45534137],\n",
       "           [-0.45534137]]]],\n",
       " \n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       " \n",
       "        [[[[-0.50422347],\n",
       "           [-0.50422347],\n",
       "           [-0.50422347],\n",
       "           ...,\n",
       "           [-0.50422347],\n",
       "           [-0.50422347],\n",
       "           [-0.50422347]],\n",
       " \n",
       "          [[-0.50422347],\n",
       "           [-0.50422347],\n",
       "           [-0.50422347],\n",
       "           ...,\n",
       "           [-0.50422347],\n",
       "           [-0.50422347],\n",
       "           [-0.50422347]],\n",
       " \n",
       "          [[-0.50422347],\n",
       "           [-0.50422347],\n",
       "           [-0.50422347],\n",
       "           ...,\n",
       "           [-0.50422347],\n",
       "           [-0.50422347],\n",
       "           [-0.50422347]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.50422347],\n",
       "           [-0.50422347],\n",
       "           [-0.50422347],\n",
       "           ...,\n",
       "           [-0.50422347],\n",
       "           [-0.50422347],\n",
       "           [-0.50422347]],\n",
       " \n",
       "          [[-0.50422347],\n",
       "           [-0.50422347],\n",
       "           [-0.50422347],\n",
       "           ...,\n",
       "           [-0.50422347],\n",
       "           [-0.50422347],\n",
       "           [-0.50422347]],\n",
       " \n",
       "          [[-0.50422347],\n",
       "           [-0.50422347],\n",
       "           [-0.50422347],\n",
       "           ...,\n",
       "           [-0.50422347],\n",
       "           [-0.50422347],\n",
       "           [-0.50422347]]],\n",
       " \n",
       " \n",
       "         [[[-0.49507442],\n",
       "           [-0.49507442],\n",
       "           [-0.49507442],\n",
       "           ...,\n",
       "           [-0.49507442],\n",
       "           [-0.49507442],\n",
       "           [-0.49507442]],\n",
       " \n",
       "          [[-0.49507442],\n",
       "           [-0.49507442],\n",
       "           [-0.49507442],\n",
       "           ...,\n",
       "           [-0.49507442],\n",
       "           [-0.49507442],\n",
       "           [-0.49507442]],\n",
       " \n",
       "          [[-0.49507442],\n",
       "           [-0.49507442],\n",
       "           [-0.49507442],\n",
       "           ...,\n",
       "           [-0.49507442],\n",
       "           [-0.49507442],\n",
       "           [-0.49507442]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.49507442],\n",
       "           [-0.49507442],\n",
       "           [-0.49507442],\n",
       "           ...,\n",
       "           [-0.49507442],\n",
       "           [-0.49507442],\n",
       "           [-0.49507442]],\n",
       " \n",
       "          [[-0.49507442],\n",
       "           [-0.49507442],\n",
       "           [-0.49507442],\n",
       "           ...,\n",
       "           [-0.49507442],\n",
       "           [-0.49507442],\n",
       "           [-0.49507442]],\n",
       " \n",
       "          [[-0.49507442],\n",
       "           [-0.49507442],\n",
       "           [-0.49507442],\n",
       "           ...,\n",
       "           [-0.49507442],\n",
       "           [-0.49507442],\n",
       "           [-0.49507442]]],\n",
       " \n",
       " \n",
       "         [[[-0.41726464],\n",
       "           [-0.41726464],\n",
       "           [-0.41726464],\n",
       "           ...,\n",
       "           [-0.41726464],\n",
       "           [-0.41726464],\n",
       "           [-0.41726464]],\n",
       " \n",
       "          [[-0.41726464],\n",
       "           [-0.41726464],\n",
       "           [-0.41726464],\n",
       "           ...,\n",
       "           [-0.41726464],\n",
       "           [-0.41726464],\n",
       "           [-0.41726464]],\n",
       " \n",
       "          [[-0.41726464],\n",
       "           [-0.41726464],\n",
       "           [-0.41726464],\n",
       "           ...,\n",
       "           [-0.41726464],\n",
       "           [-0.41726464],\n",
       "           [-0.41726464]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.41726464],\n",
       "           [-0.41726464],\n",
       "           [-0.41726464],\n",
       "           ...,\n",
       "           [-0.41726464],\n",
       "           [-0.41726464],\n",
       "           [-0.41726464]],\n",
       " \n",
       "          [[-0.41726464],\n",
       "           [-0.41726464],\n",
       "           [-0.41726464],\n",
       "           ...,\n",
       "           [-0.41726464],\n",
       "           [-0.41726464],\n",
       "           [-0.41726464]],\n",
       " \n",
       "          [[-0.41726464],\n",
       "           [-0.41726464],\n",
       "           [-0.41726464],\n",
       "           ...,\n",
       "           [-0.41726464],\n",
       "           [-0.41726464],\n",
       "           [-0.41726464]]],\n",
       " \n",
       " \n",
       "         [[[-0.47322348],\n",
       "           [-0.47322348],\n",
       "           [-0.47322348],\n",
       "           ...,\n",
       "           [-0.47322348],\n",
       "           [-0.47322348],\n",
       "           [-0.47322348]],\n",
       " \n",
       "          [[-0.47322348],\n",
       "           [-0.47322348],\n",
       "           [-0.47322348],\n",
       "           ...,\n",
       "           [-0.47322348],\n",
       "           [-0.47322348],\n",
       "           [-0.47322348]],\n",
       " \n",
       "          [[-0.47322348],\n",
       "           [-0.47322348],\n",
       "           [-0.47322348],\n",
       "           ...,\n",
       "           [-0.47322348],\n",
       "           [-0.47322348],\n",
       "           [-0.47322348]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.47322348],\n",
       "           [-0.47322348],\n",
       "           [-0.47322348],\n",
       "           ...,\n",
       "           [-0.47322348],\n",
       "           [-0.47322348],\n",
       "           [-0.47322348]],\n",
       " \n",
       "          [[-0.47322348],\n",
       "           [-0.47322348],\n",
       "           [-0.47322348],\n",
       "           ...,\n",
       "           [-0.47322348],\n",
       "           [-0.47322348],\n",
       "           [-0.47322348]],\n",
       " \n",
       "          [[-0.47322348],\n",
       "           [-0.47322348],\n",
       "           [-0.47322348],\n",
       "           ...,\n",
       "           [-0.47322348],\n",
       "           [-0.47322348],\n",
       "           [-0.47322348]]]],\n",
       " \n",
       " \n",
       " \n",
       "        [[[[-0.529575  ],\n",
       "           [-0.529575  ],\n",
       "           [-0.529575  ],\n",
       "           ...,\n",
       "           [-0.529575  ],\n",
       "           [-0.529575  ],\n",
       "           [-0.529575  ]],\n",
       " \n",
       "          [[-0.529575  ],\n",
       "           [-0.529575  ],\n",
       "           [-0.529575  ],\n",
       "           ...,\n",
       "           [-0.529575  ],\n",
       "           [-0.529575  ],\n",
       "           [-0.529575  ]],\n",
       " \n",
       "          [[-0.529575  ],\n",
       "           [-0.529575  ],\n",
       "           [-0.529575  ],\n",
       "           ...,\n",
       "           [-0.529575  ],\n",
       "           [-0.529575  ],\n",
       "           [-0.529575  ]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.529575  ],\n",
       "           [-0.529575  ],\n",
       "           [-0.529575  ],\n",
       "           ...,\n",
       "           [-0.529575  ],\n",
       "           [-0.529575  ],\n",
       "           [-0.529575  ]],\n",
       " \n",
       "          [[-0.529575  ],\n",
       "           [-0.529575  ],\n",
       "           [-0.529575  ],\n",
       "           ...,\n",
       "           [-0.529575  ],\n",
       "           [-0.529575  ],\n",
       "           [-0.529575  ]],\n",
       " \n",
       "          [[-0.529575  ],\n",
       "           [-0.529575  ],\n",
       "           [-0.529575  ],\n",
       "           ...,\n",
       "           [-0.529575  ],\n",
       "           [-0.529575  ],\n",
       "           [-0.529575  ]]],\n",
       " \n",
       " \n",
       "         [[[-0.25574905],\n",
       "           [-0.25574905],\n",
       "           [-0.25574905],\n",
       "           ...,\n",
       "           [-0.25574905],\n",
       "           [-0.25574905],\n",
       "           [-0.25574905]],\n",
       " \n",
       "          [[-0.25574905],\n",
       "           [-0.25574905],\n",
       "           [-0.25574905],\n",
       "           ...,\n",
       "           [-0.25574905],\n",
       "           [-0.25574905],\n",
       "           [-0.25574905]],\n",
       " \n",
       "          [[-0.25574905],\n",
       "           [-0.25574905],\n",
       "           [-0.25574905],\n",
       "           ...,\n",
       "           [-0.25574905],\n",
       "           [-0.25574905],\n",
       "           [-0.25574905]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.25574905],\n",
       "           [-0.25574905],\n",
       "           [-0.25574905],\n",
       "           ...,\n",
       "           [-0.25574905],\n",
       "           [-0.25574905],\n",
       "           [-0.25574905]],\n",
       " \n",
       "          [[-0.25574905],\n",
       "           [-0.25574905],\n",
       "           [-0.25574905],\n",
       "           ...,\n",
       "           [-0.25574905],\n",
       "           [-0.25574905],\n",
       "           [-0.25574905]],\n",
       " \n",
       "          [[-0.25574905],\n",
       "           [-0.25574905],\n",
       "           [-0.25574905],\n",
       "           ...,\n",
       "           [-0.25574905],\n",
       "           [-0.25574905],\n",
       "           [-0.25574905]]],\n",
       " \n",
       " \n",
       "         [[[-0.55848736],\n",
       "           [-0.55848736],\n",
       "           [-0.55848736],\n",
       "           ...,\n",
       "           [-0.55848736],\n",
       "           [-0.55848736],\n",
       "           [-0.55848736]],\n",
       " \n",
       "          [[-0.55848736],\n",
       "           [-0.55848736],\n",
       "           [-0.55848736],\n",
       "           ...,\n",
       "           [-0.55848736],\n",
       "           [-0.55848736],\n",
       "           [-0.55848736]],\n",
       " \n",
       "          [[-0.55848736],\n",
       "           [-0.55848736],\n",
       "           [-0.55848736],\n",
       "           ...,\n",
       "           [-0.55848736],\n",
       "           [-0.55848736],\n",
       "           [-0.55848736]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.55848736],\n",
       "           [-0.55848736],\n",
       "           [-0.55848736],\n",
       "           ...,\n",
       "           [-0.55848736],\n",
       "           [-0.55848736],\n",
       "           [-0.55848736]],\n",
       " \n",
       "          [[-0.55848736],\n",
       "           [-0.55848736],\n",
       "           [-0.55848736],\n",
       "           ...,\n",
       "           [-0.55848736],\n",
       "           [-0.55848736],\n",
       "           [-0.55848736]],\n",
       " \n",
       "          [[-0.55848736],\n",
       "           [-0.55848736],\n",
       "           [-0.55848736],\n",
       "           ...,\n",
       "           [-0.55848736],\n",
       "           [-0.55848736],\n",
       "           [-0.55848736]]],\n",
       " \n",
       " \n",
       "         [[[-0.25994283],\n",
       "           [-0.25994283],\n",
       "           [-0.25994283],\n",
       "           ...,\n",
       "           [-0.25994283],\n",
       "           [-0.25994283],\n",
       "           [-0.25994283]],\n",
       " \n",
       "          [[-0.25994283],\n",
       "           [-0.25994283],\n",
       "           [-0.25994283],\n",
       "           ...,\n",
       "           [-0.25994283],\n",
       "           [-0.25994283],\n",
       "           [-0.25994283]],\n",
       " \n",
       "          [[-0.25994283],\n",
       "           [-0.25994283],\n",
       "           [-0.25994283],\n",
       "           ...,\n",
       "           [-0.25994283],\n",
       "           [-0.25994283],\n",
       "           [-0.25994283]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.25994283],\n",
       "           [-0.25994283],\n",
       "           [-0.25994283],\n",
       "           ...,\n",
       "           [-0.25994283],\n",
       "           [-0.25994283],\n",
       "           [-0.25994283]],\n",
       " \n",
       "          [[-0.25994283],\n",
       "           [-0.25994283],\n",
       "           [-0.25994283],\n",
       "           ...,\n",
       "           [-0.25994283],\n",
       "           [-0.25994283],\n",
       "           [-0.25994283]],\n",
       " \n",
       "          [[-0.25994283],\n",
       "           [-0.25994283],\n",
       "           [-0.25994283],\n",
       "           ...,\n",
       "           [-0.25994283],\n",
       "           [-0.25994283],\n",
       "           [-0.25994283]]]],\n",
       " \n",
       " \n",
       " \n",
       "        [[[[-0.3653515 ],\n",
       "           [-0.3653515 ],\n",
       "           [-0.3653515 ],\n",
       "           ...,\n",
       "           [-0.3653515 ],\n",
       "           [-0.3653515 ],\n",
       "           [-0.3653515 ]],\n",
       " \n",
       "          [[-0.3653515 ],\n",
       "           [-0.3653515 ],\n",
       "           [-0.3653515 ],\n",
       "           ...,\n",
       "           [-0.3653515 ],\n",
       "           [-0.3653515 ],\n",
       "           [-0.3653515 ]],\n",
       " \n",
       "          [[-0.3653515 ],\n",
       "           [-0.3653515 ],\n",
       "           [-0.3653515 ],\n",
       "           ...,\n",
       "           [-0.3653515 ],\n",
       "           [-0.3653515 ],\n",
       "           [-0.3653515 ]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.3653515 ],\n",
       "           [-0.3653515 ],\n",
       "           [-0.3653515 ],\n",
       "           ...,\n",
       "           [-0.3653515 ],\n",
       "           [-0.3653515 ],\n",
       "           [-0.3653515 ]],\n",
       " \n",
       "          [[-0.3653515 ],\n",
       "           [-0.3653515 ],\n",
       "           [-0.3653515 ],\n",
       "           ...,\n",
       "           [-0.3653515 ],\n",
       "           [-0.3653515 ],\n",
       "           [-0.3653515 ]],\n",
       " \n",
       "          [[-0.3653515 ],\n",
       "           [-0.3653515 ],\n",
       "           [-0.3653515 ],\n",
       "           ...,\n",
       "           [-0.3653515 ],\n",
       "           [-0.3653515 ],\n",
       "           [-0.3653515 ]]],\n",
       " \n",
       " \n",
       "         [[[-0.43164185],\n",
       "           [-0.43164185],\n",
       "           [-0.43164185],\n",
       "           ...,\n",
       "           [-0.43164185],\n",
       "           [-0.43164185],\n",
       "           [-0.43164185]],\n",
       " \n",
       "          [[-0.43164185],\n",
       "           [-0.43164185],\n",
       "           [-0.43164185],\n",
       "           ...,\n",
       "           [-0.43164185],\n",
       "           [-0.43164185],\n",
       "           [-0.43164185]],\n",
       " \n",
       "          [[-0.43164185],\n",
       "           [-0.43164185],\n",
       "           [-0.43164185],\n",
       "           ...,\n",
       "           [-0.43164185],\n",
       "           [-0.43164185],\n",
       "           [-0.43164185]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.43164185],\n",
       "           [-0.43164185],\n",
       "           [-0.43164185],\n",
       "           ...,\n",
       "           [-0.43164185],\n",
       "           [-0.43164185],\n",
       "           [-0.43164185]],\n",
       " \n",
       "          [[-0.43164185],\n",
       "           [-0.43164185],\n",
       "           [-0.43164185],\n",
       "           ...,\n",
       "           [-0.43164185],\n",
       "           [-0.43164185],\n",
       "           [-0.43164185]],\n",
       " \n",
       "          [[-0.43164185],\n",
       "           [-0.43164185],\n",
       "           [-0.43164185],\n",
       "           ...,\n",
       "           [-0.43164185],\n",
       "           [-0.43164185],\n",
       "           [-0.43164185]]],\n",
       " \n",
       " \n",
       "         [[[-0.38939473],\n",
       "           [-0.38939473],\n",
       "           [-0.38939473],\n",
       "           ...,\n",
       "           [-0.38939473],\n",
       "           [-0.38939473],\n",
       "           [-0.38939473]],\n",
       " \n",
       "          [[-0.38939473],\n",
       "           [-0.38939473],\n",
       "           [-0.38939473],\n",
       "           ...,\n",
       "           [-0.38939473],\n",
       "           [-0.38939473],\n",
       "           [-0.38939473]],\n",
       " \n",
       "          [[-0.38939473],\n",
       "           [-0.38939473],\n",
       "           [-0.38939473],\n",
       "           ...,\n",
       "           [-0.38939473],\n",
       "           [-0.38939473],\n",
       "           [-0.38939473]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.38939473],\n",
       "           [-0.38939473],\n",
       "           [-0.38939473],\n",
       "           ...,\n",
       "           [-0.38939473],\n",
       "           [-0.38939473],\n",
       "           [-0.38939473]],\n",
       " \n",
       "          [[-0.38939473],\n",
       "           [-0.38939473],\n",
       "           [-0.38939473],\n",
       "           ...,\n",
       "           [-0.38939473],\n",
       "           [-0.38939473],\n",
       "           [-0.38939473]],\n",
       " \n",
       "          [[-0.38939473],\n",
       "           [-0.38939473],\n",
       "           [-0.38939473],\n",
       "           ...,\n",
       "           [-0.38939473],\n",
       "           [-0.38939473],\n",
       "           [-0.38939473]]],\n",
       " \n",
       " \n",
       "         [[[-0.36683136],\n",
       "           [-0.36683136],\n",
       "           [-0.36683136],\n",
       "           ...,\n",
       "           [-0.36683136],\n",
       "           [-0.36683136],\n",
       "           [-0.36683136]],\n",
       " \n",
       "          [[-0.36683136],\n",
       "           [-0.36683136],\n",
       "           [-0.36683136],\n",
       "           ...,\n",
       "           [-0.36683136],\n",
       "           [-0.36683136],\n",
       "           [-0.36683136]],\n",
       " \n",
       "          [[-0.36683136],\n",
       "           [-0.36683136],\n",
       "           [-0.36683136],\n",
       "           ...,\n",
       "           [-0.36683136],\n",
       "           [-0.36683136],\n",
       "           [-0.36683136]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.36683136],\n",
       "           [-0.36683136],\n",
       "           [-0.36683136],\n",
       "           ...,\n",
       "           [-0.36683136],\n",
       "           [-0.36683136],\n",
       "           [-0.36683136]],\n",
       " \n",
       "          [[-0.36683136],\n",
       "           [-0.36683136],\n",
       "           [-0.36683136],\n",
       "           ...,\n",
       "           [-0.36683136],\n",
       "           [-0.36683136],\n",
       "           [-0.36683136]],\n",
       " \n",
       "          [[-0.36683136],\n",
       "           [-0.36683136],\n",
       "           [-0.36683136],\n",
       "           ...,\n",
       "           [-0.36683136],\n",
       "           [-0.36683136],\n",
       "           [-0.36683136]]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(32, 4), dtype=float32, numpy=\n",
       " array([[  1.,   0.,   1.,  -6.],\n",
       "        [  8.,   2.,   9.,   8.],\n",
       "        [  3.,  -3.,   0.,  -4.],\n",
       "        [  3.,   2.,   8.,   4.],\n",
       "        [  2.,   0.,   8.,   4.],\n",
       "        [  2.,   2.,  10.,   4.],\n",
       "        [  2.,   2.,   4.,  -4.],\n",
       "        [  1.,  -8.,  -6., -12.],\n",
       "        [  8.,   1.,   9.,   9.],\n",
       "        [  3.,   0.,   2.,  -6.],\n",
       "        [  8.,   4.,   7.,   4.],\n",
       "        [  4.,   2.,   4.,  -3.],\n",
       "        [  4.,   2.,   8.,   6.],\n",
       "        [  5.,   5.,  11.,   8.],\n",
       "        [  4.,  -3.,   5.,  -3.],\n",
       "        [  4.,  -2.,   2.,  -7.],\n",
       "        [  7.,   1.,   4.,  -1.],\n",
       "        [  9.,   9.,  18.,  15.],\n",
       "        [  9.,   0.,   1.,  -6.],\n",
       "        [  3.,  -6.,  -2.,  -7.],\n",
       "        [  7.,   7.,   8.,   2.],\n",
       "        [  1.,   1.,  10.,   5.],\n",
       "        [  5.,  -2.,   4.,  -2.],\n",
       "        [  3.,  -4.,   2.,   1.],\n",
       "        [  1.,  -7.,  -6.,  -8.],\n",
       "        [  6.,  -2.,   7.,   5.],\n",
       "        [  5.,  -4.,   4.,  -5.],\n",
       "        [  4.,   0.,   8.,   7.],\n",
       "        [  4.,  -3.,   5.,   3.],\n",
       "        [  6.,   3.,   6.,   1.],\n",
       "        [  2.,   1.,   9.,   8.],\n",
       "        [  5.,  -2.,   7.,   5.]], dtype=float32)>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create training and testing data sets \n",
    "train_dataset = prepare_data(train_ds, 32, 4)\n",
    "test_dataset = prepare_data(test_ds, 32, 4)\n",
    "\n",
    "# print how a batch looks like\n",
    "iterator = iter(train_dataset)\n",
    "iterator.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 CNN and LSTM Network\n",
    "\n",
    "- first part: basic CNN structure\n",
    "- should extract vector representations from each MNIST image using Conv2D layers as well as (global) pooling or Flatten layers\n",
    "- Conv2D layer can be called on a batch of sequences of images, where the time dimension is in the second axis; time dimension will then be processed like a second batch dimension -> extended batch shape\n",
    "- while Conv2D layers accept a (batch, sequence-length, image) data structure with their extended batch size functionality, for the pooling layers to work correctly they need to be wrapped in TensorFlow’s TimeDistributed layers!\n",
    "- Once all images are encoded as vectors, the shape of the tensor should be (batch, sequence-length, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):  \n",
    "        super().__init__()\n",
    "        \n",
    "        # layers\n",
    "        self.conv1 = TimeDistributed(Conv2D(filters=24, kernel_size=3, padding='same', activation='relu'))\n",
    "        self.conv2 = TimeDistributed(Conv2D(filters=24, kernel_size=3, padding='same', activation='relu'))\n",
    "        self.maxpool = TimeDistributed(MaxPooling2D(pool_size=2, strides=2))\n",
    "\n",
    "        self.conv3 = TimeDistributed(Conv2D(filters=48, kernel_size=3, padding='same', activation='relu'))\n",
    "        self.conv4 = TimeDistributed(Conv2D(filters=48, kernel_size=3, padding='same', activation='relu'))\n",
    "        self.globalpool = TimeDistributed(GlobalAvgPool2D())\n",
    "\n",
    "        self.out = TimeDistributed(Dense(10, activation='softmax'))\n",
    "        \n",
    "    @tf.function\n",
    "    def __call__(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.globalpool(x)\n",
    "        \n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 LSTM AbstractRNNcell layer\n",
    "\n",
    "- subclass the AbstractRNNCell layer and implement its methods and define the required properties (state size, output size, and get initial state, which determines the initial hidden and cell state of the LSTM (usually tensors filled with zeros))\n",
    "- LSTM-cell layer’s call method should take one (batch of) feature vector(s) as its input, along with the ”states”, a list containing the different state tensors of the LSTM cell (cell state and hidden state!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(tf.keras.layers.AbstractRNNCell):\n",
    "\n",
    "    def __init__(self, num_hidden_states, num_cell_states, batch_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_states = num_hidden_states\n",
    "        self.cell_states = num_cell_states\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.forget_gate = tf.keras.layers.Dense(self.hidden_states, activation='sigmoid')\n",
    "        self.input_gate = tf.keras.layers.Dense(self.hidden_states, activation='sigmoid')\n",
    "        self.cell_gate = tf.keras.layers.Dense(self.cell_states, activation='tanh')\n",
    "        self.output_gate = tf.keras.layers.Dense(self.cell_states, activation='sigmoid')\n",
    "    \n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return [tf.TensorShape([self.hidden_states]), \n",
    "                tf.TensorShape([self.cell_states])]\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return [tf.TensorShape([self.cell_states])]\n",
    "    \n",
    "    def get_initial_state(self, inputs=None, batch_size=None, dtype=None):\n",
    "        return [tf.zeros([self.batch_size, self.hidden_states], dtype=\"float32\"), \n",
    "                tf.zeros([self.batch_size, self.cell_states], dtype=\"float32\")]\n",
    "\n",
    "    # call method takes (batch of) feature vector(s) as its input, along with the ”states” \n",
    "    def call(self, inputs, states):\n",
    "        \n",
    "        hidden_state = states[0]\n",
    "        cell_state = states[1]\n",
    "        \n",
    "        forget = self.forget_gate(tf.concat([inputs, hidden_state], 1))\n",
    "        input_update = self.input_gate(tf.concat([inputs, hidden_state], 1))\n",
    "        cell_update = self.cell_gate(tf.concat([inputs, hidden_state], 1))\n",
    "        \n",
    "        new_cell_state = forget * cell_state + input_update * cell_update\n",
    "        \n",
    "        output_update = self.output_gate(tf.concat([inputs, hidden_state], 1))\n",
    "        \n",
    "        output = output_update * tf.keras.activations.tanh(new_cell_state)\n",
    "        \n",
    "        # return output and the list of new states of the layers\n",
    "        return output, [output, new_cell_state]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Wrapping LSTM Cell layer with RNN layer\n",
    "\n",
    "- tf.keras.layers.RNN takes an instance of your LSTM cell as the first argument in its constructor\n",
    "- the ”wrapper” RNN layer then takes the sequence of vector representations of the mnist images as its input (batch, seq len, feature dim)\n",
    "- need to specify whether you want the RNN wrapper layer to return the output of your LSTM-cell for every time-step or only for the last step (with the argument return sequences=True) -> generally task-dependent (so think about what makes sense here)\n",
    "- for speed-ups (at the cost of memory usage), set the ”unroll” argument to True\n",
    "\n",
    "### 2.5 Computing model output\n",
    "\n",
    "- could (if the task demands it) use the same Dense layer to predict targets for all time-steps; but likely do not want to have a Dense layer for each time-step’s target prediction (potential for overfitting!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(tf.keras.Model):\n",
    "    def __init__(self, cnn, lstm_cell, optimizer, loss_function):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.cnn = CNN()\n",
    "        self.lstm_cell = LSTMCell(1,1,20)\n",
    "        self.output_layer = Dense(36,activation='softmax')\n",
    "\n",
    "        self.metrics_list = [\n",
    "            tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
    "            tf.keras.metrics.Mean(name=\"loss\")]\n",
    "\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_function = loss_function\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return self.metrics_list\n",
    "    \n",
    "    def reset_metrics(self):\n",
    "        for metric in self.metrics:\n",
    "            metric.reset_state()\n",
    "    \n",
    "    def call(self, sequence):\n",
    "        cnn_output = cnn.call(sequence)\n",
    "        cnn_number = tf.argmax(cnn_output, axis=-1)\n",
    "        lstm_output = self.lstm_cell(cnn_output)\n",
    "        output = self.output_layer(lstm_output)\n",
    "        return output\n",
    "    \n",
    "    @tf.function\n",
    "    def training_step(self, image, label):\n",
    "\n",
    "        with tf.GradientTape() as tape: \n",
    "            prediction = self(image, training = True)\n",
    "\n",
    "            loss = self.loss_function(label, prediction)\n",
    "\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients,self.trainable_variables))\n",
    "        self.metrics[0].update_state(label, prediction)\n",
    "        self.metrics[1].update_state(loss)  \n",
    "\n",
    "    @tf.function\n",
    "    def test_step(self, data):\n",
    "        image, label = data\n",
    "        prediction = self(image, training = False)\n",
    "        loss = self.loss_function(label, prediction)\n",
    "        self.metrics[0].update_state(label, prediction)\n",
    "        self.metrics[1].update_state(loss)\n",
    "        return {m.name : m.result() for m in self.metrics}        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Training\n",
    "\n",
    "- own training loop or model.compile and model.fit methods\n",
    "- track experiments properly, save configs (e.g. hyperparameters) of settings, save logs (e.g. with Tensorboard) and checkpoint the model’s weights (or even the complete model)\n",
    "- visualize your results (e.g default history callback of model.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "model = LSTMModel(CNN, LSTMCell, optimizer, loss)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = \"Run_1\"\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logging_callback = tf.keras.callbacks.TensorBoard(log_dir=f\"./logs/{EXPERIMENT_NAME}/{current_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\berit\\AppData\\Local\\Temp\\__autograph_generated_filezzlgzx1n.py\", line 10, in tf__call\n        cnn_output = ag__.converted_call(ag__.ld(self).cnn, (ag__.ld(sequence),), None, fscope)\n\n    TypeError: Exception encountered when calling layer \"lstm_model\" \"                 f\"(type LSTMModel).\n    \n    in user code:\n    \n        File \"C:\\Users\\berit\\AppData\\Local\\Temp\\ipykernel_17404\\2864297913.py\", line 25, in call  *\n            cnn_output = self.cnn(sequence)\n    \n        TypeError: CNN.__init__() takes 1 positional argument but 2 were given\n    \n    \n    Call arguments received by layer \"lstm_model\" \"                 f\"(type LSTMModel):\n      • sequence=tf.Tensor(shape=(None, 4, 28, 28, 1), dtype=float32)\n      • training=True\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlogging_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileeq31yf89.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filezzlgzx1n.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, sequence, training)\u001b[0m\n\u001b[0;32m      8\u001b[0m do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m      9\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m---> 10\u001b[0m cnn_output \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m cnn_number \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39margmax, (ag__\u001b[38;5;241m.\u001b[39mld(cnn_output),), \u001b[38;5;28mdict\u001b[39m(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), fscope)\n\u001b[0;32m     12\u001b[0m lstm_output \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mlstm_cell, (ag__\u001b[38;5;241m.\u001b[39mld(cnn_output),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\berit\\AppData\\Local\\Temp\\__autograph_generated_filezzlgzx1n.py\", line 10, in tf__call\n        cnn_output = ag__.converted_call(ag__.ld(self).cnn, (ag__.ld(sequence),), None, fscope)\n\n    TypeError: Exception encountered when calling layer \"lstm_model\" \"                 f\"(type LSTMModel).\n    \n    in user code:\n    \n        File \"C:\\Users\\berit\\AppData\\Local\\Temp\\ipykernel_17404\\2864297913.py\", line 25, in call  *\n            cnn_output = self.cnn(sequence)\n    \n        TypeError: CNN.__init__() takes 1 positional argument but 2 were given\n    \n    \n    Call arguments received by layer \"lstm_model\" \"                 f\"(type LSTMModel):\n      • sequence=tf.Tensor(shape=(None, 4, 28, 28, 1), dtype=float32)\n      • training=True\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, validation_data=test_dataset, initial_epoch=0, epochs=5, callbacks=([logging_callback]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the complete model (incl. optimizer state, loss function, metrics etc.)\n",
    "# ideally save to google drive if you're using colab\n",
    "model.save(\"saved_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model and resume training where we had to stop\n",
    "loaded_model = tf.keras.models.load_model(\"saved_model\", custom_objects={\"LSTMCell\": LSTMCell,\n",
    "                                                                         \"LSTMModel\": LSTMModel})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.legend(labels=[\"training\",\"validation\"])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Categorical Crossentropy Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=\"logs/Run_1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why doesn't it work? Struggles and possible mistakes:\n",
    "\n",
    "* We struggled to understand what was being asked of us for the preprocessing data portion, i.e. how the data was supposed to look like at the end (especially the targets).\n",
    "* After trying our best at understanding what was necessary to prepare the data, it was still challenging to get it to work. We struggled with many errors using the windows method, perhaps we need a better understanding of how to implement all of its functions. We tried to utilize other functionalities and brought the data into a shape that seemd sensible to us.\n",
    "* We decided to write the model even if we weren't sure if the data shape would fit but unfortunatley there was no way to test the data since there always seemed to be misfitting functions between data shape - CNN structure - LSTM cell and wrapping RNN model. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iannwtf",
   "language": "python",
   "name": "iannwtf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b32be4b366388b051e7633bee8b88f892427058db1cb57d13a031e39df811307"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
