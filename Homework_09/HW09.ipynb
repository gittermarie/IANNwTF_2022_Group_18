{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa3b2c0e",
   "metadata": {},
   "source": [
    "# Homework 09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e99216cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Dense, Conv2D, AveragePooling2D, TimeDistributed, LSTM, GlobalAvgPool2D, AbstractRNNCell, MaxPooling2D, RNN\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import tqdm\n",
    "# magic line only needed in jupyter notebooks!\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e149696",
   "metadata": {},
   "source": [
    "### Dowloading Data for the Task from the Quick, Draw! Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d8dd519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "#import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "237a96af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'aircraft carrier', b'airplane', b'alarm clock', b'ambulance', b'angel', b'animal migration', b'ant', b'anvil', b'apple', b'arm']\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "categories = [line.rstrip(b'\\n') for line in urllib.request.urlopen('https://raw.githubusercontent.com/googlecreativelab/quickdraw-dataset/master/categories.txt')]\n",
    "print(categories[:10])\n",
    "category = 'candle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f5a81ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip this cell if you already downloaded the data/you have the folder containing the data\n",
    "\n",
    "# Creates a folder to download the original drawings into.\n",
    "# We chose to use the numpy format : 1x784 pixel vectors, with values going from 0 (white) to 255 (black). We reshape them later to 28x28 grids and normalize the pixel intensity to [-1, 1]\n",
    "# We reshape them later to 28x28 grids and normalize the pixel intensity to [-1, 1]\n",
    "\n",
    "#if not os.path.isdir('npy_files'):\n",
    "    #os.mkdir('npy_files')\n",
    "    \n",
    "#url = f'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/{category}.npy'  \n",
    "#urllib.request.urlretrieve(url, f'npy_files/{category}.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1842cfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141545 images to train on\n"
     ]
    }
   ],
   "source": [
    "# load images from newly created local folder\n",
    "images = np.load(f'npy_files/{category}.npy')\n",
    "print(f'{len(images)} images to train on')\n",
    "\n",
    "# amount of images for training\n",
    "train_images = images[:10000]\n",
    "# subset of the images for testing\n",
    "test_images = images[15000:17500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a8d4f7",
   "metadata": {},
   "source": [
    "## Assignment 2: GANs\n",
    "\n",
    "### 2.1 Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5fe838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global parameter: adjustable batch size\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a922550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(raw_data):\n",
    "    # create tf dataset out of numpy arrays\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(raw_data)\n",
    "    # reshap from (1, 784) to shape (28,28,1)\n",
    "    dataset = dataset.map(lambda img: tf.reshape(img, (28,28,1)))\n",
    "    # normalization of tensors\n",
    "    dataset = dataset.map(lambda img: tf.image.per_image_standardization(img))\n",
    "    # cache, shuffle, batch, prefetch\n",
    "    dataset = dataset.cache().shuffle(1000).batch(batch_size).prefetch(20)\n",
    "    \n",
    "    return dataset  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea11d360",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = data_preprocessing(train_images)\n",
    "test_ds = data_preprocessing(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09596c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 28, 28, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check shape of the data   \n",
    "list(train_ds.as_numpy_iterator())[1]\n",
    "np.shape(list(train_ds.as_numpy_iterator())[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10996587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_image(dataset):\n",
    "    # get an image from the dataset\n",
    "    img = next(iter(dataset))\n",
    "\n",
    "    # get the first image from the batch\n",
    "    img = img[0]\n",
    "\n",
    "    # Remove the extra dimension\n",
    "    #img = tf.squeeze(img, axis=-1)\n",
    "\n",
    "    # plot the image\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9db800a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize how a data point looks like \n",
    "print_image(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f6057f",
   "metadata": {},
   "source": [
    "### 2.2 The GAN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2200c61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(tf.keras.Model):\n",
    "    \n",
    "    # perform downsampling and output a vector of probabilities indicating whether the input was fake or real\n",
    "    # basically just like a CNN architecture for a binary classification task\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # list of all layers to iterate through during call\n",
    "        self.layer_list = []\n",
    "        \n",
    "        # layers\n",
    "        self.layer_list.append(Conv2D(filters=24, kernel_size=3, padding='same', activation='relu'))\n",
    "        self.layer_list.append(tf.keras.layers.BatchNormalization())\n",
    "        #self.layer_list.append(tf.keras.layers.Dropout(0.2))\n",
    "        self.layer_list.append(Conv2D(filters=24, kernel_size=3, padding='same', activation='relu'))\n",
    "        self.layer_list.append(MaxPooling2D(pool_size=2, strides=2))\n",
    "\n",
    "        self.layer_list.append(Conv2D(filters=48, kernel_size=3, padding='same', activation='relu'))\n",
    "        self.layer_list.append(tf.keras.layers.BatchNormalization())\n",
    "        #self.layer_list.append(tf.keras.layers.Dropout(0.2))\n",
    "        self.layer_list.append(Conv2D(filters=48, kernel_size=3, padding='same', activation='relu'))\n",
    "        self.layer_list.append(GlobalAvgPool2D())\n",
    "        \n",
    "        # a Dense layer with a single neuron in the end\n",
    "        self.layer_list.append(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "    # call funtion\n",
    "    # training flag to use certain optimization and regularization techniques -> BatchNorm and Dropout\n",
    "    @tf.function\n",
    "    def call(self, x, training = False):\n",
    "        for layer in self.layer_list:\n",
    "            x = layer(x, training=training)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5bf66ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(tf.keras.Model):\n",
    "    \n",
    "    # takes a random point from the latent space and returns a generated image\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # list of all layers to iterate through during call\n",
    "        self.layer_list = []\n",
    "        \n",
    "        # layers\n",
    "        # latent space (size adjustable, but start with 100) comes as a 1d vector\n",
    "        self.layer_list.append(Dense(128, activation='relu', input_shape=(100,)))\n",
    "        # reshape such that we have a 2D image\n",
    "        self.layer_list.append(tf.keras.layers.Reshape((8,8,2)))\n",
    "        \n",
    "        # convolutional layers with upsampling in between and batch normalization/dropout\n",
    "        self.layer_list.append(Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
    "        self.layer_list.append(tf.keras.layers.BatchNormalization())\n",
    "        #self.layer_list.append(tf.keras.layers.Dropout(0.2))\n",
    "        # upsampling technique (Conv2DTranspose) - even-sized kernels in transposed convolutions\n",
    "        self.layer_list.append(tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=4, padding='same', activation='relu'))\n",
    "        self.layer_list.append(Conv2D(filters=48, kernel_size=3, padding='same', activation='relu'))\n",
    "        self.layer_list.append(tf.keras.layers.BatchNormalization())\n",
    "        #self.layer_list.append(tf.keras.layers.Dropout(0.2))\n",
    "        \n",
    "        # in the last layer, perform a convolution with 1 feature map and tanh activation\n",
    "        self.layer_list.append(Conv2D(filters=1, kernel_size=3, padding='same', activation='tanh'))\n",
    "          \n",
    "        \n",
    "    # call funtion\n",
    "    # training flag to use certain optimization and regularization techniques -> BatchNorm and Dropout\n",
    "    @tf.function\n",
    "    def call(self, x, training = False):\n",
    "        for layer in self.layer_list:\n",
    "            x = layer(x, training=training)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e64c955",
   "metadata": {},
   "source": [
    "Much help was provided by the code from this Tensorflow Tutorial:\n",
    "https://www.tensorflow.org/tutorials/generative/dcgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7c93338",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        # optimzer, metrics, loss\n",
    "        self.optimizer_generator = tf.keras.optimizers.Adam()\n",
    "        self.optimizer_discriminator = tf.keras.optimizers.Adam()\n",
    "\n",
    "        self.metrics_list = [\n",
    "                        tf.keras.metrics.Mean(name=\"generator_loss\"),\n",
    "                        tf.keras.metrics.Mean(name=\"discriminator_loss\"),\n",
    "                        #tf.keras.metrics.BinaryAccuracy(name=\"discriminator_acc\") \n",
    "                       ]\n",
    "\n",
    "        self.loss_function = tf.keras.losses.BinaryCrossentropy()\n",
    "        \n",
    "        self.discriminator = Discriminator() \n",
    "        self.generator = Generator() \n",
    "        \n",
    "        # for evaluation, random latent vectors generated before training and feed through the generator regularly\n",
    "        # random noise = input to generator; size of noise vector is the size of latent space\n",
    "        self.eval_noise = tf.random.normal([batch_size,100]) #? this is also my random seed for comparison...i think\n",
    "\n",
    "        \n",
    "    # call funtion\n",
    "    @tf.function\n",
    "    def call(self, x, training=False):\n",
    "        x = self.generator(x) \n",
    "        x = self.discriminator(x)\n",
    "        return x\n",
    "    \n",
    "    # metrics property\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return self.metrics_list\n",
    "        # return a list with all metrics in the model\n",
    "\n",
    "    # reset all metrics objects\n",
    "    def reset_metrics(self):\n",
    "        for metric in self.metrics:\n",
    "            metric.reset_states()\n",
    "    \n",
    "    # train step method\n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "        \n",
    "        # create random noise = input to generator; size of noise vector is the size of latent space \n",
    "        noise = tf.random.normal([batch_size, 100]) #????\n",
    "        \n",
    "        # calculate and backpropagate gradients\n",
    "        with tf.GradientTape() as generator_tape, tf.GradientTape() as discriminator_tape:\n",
    "            \n",
    "            # discriminator sees a batch of true images and a batch of the generated images\n",
    "            generated_images = self.generator(noise, training =True)\n",
    "            true_images = data\n",
    "            # predictions\n",
    "            output_generated = self.discriminator(generated_images, training=True)\n",
    "            output_true = self.discriminator(true_images, training=True)\n",
    "            # losses \n",
    "            # loss of the discriminator is based on how well the discriminator detected fake images as fake and real images as real\n",
    "            # BCE between the discriminator’s output on the real images and all labels = 1\n",
    "            loss_true = self.loss_function(tf.ones_like(output_true), output_true)\n",
    "            # BCE between the discriminator’s output on fake images and all labels = 0\n",
    "            loss_generated = self.loss_function(tf.zeros_like(output_generated), output_generated)\n",
    "            # add together to get the resulting loss of discriminator\n",
    "            loss_discriminator = loss_true + loss_generated\n",
    "            \n",
    "            # loss of the generator is estimated by how well the generator was able to fool the discriminator\n",
    "            loss_generator = self.loss_function(tf.ones_like(output_generated), output_generated)\n",
    "\n",
    "            \n",
    "            # accuracy of discriminator? \n",
    "            # acc_discriminator = \n",
    "            \n",
    "            # update metrics\n",
    "            self.metrics[0].update_state(loss_generator)\n",
    "            self.metrics[1].update_state(loss_discriminator)\n",
    "            #self.metrics[2].update_state(acc_discriminator)\n",
    "            \n",
    "        \n",
    "        # calculate gradients for both based on respective loss\n",
    "        gradients_generator = generator_tape.gradient(loss_generator, self.trainable_variables)\n",
    "        gradients_discriminator = discriminator_tape.gradient(loss_discriminator, self.trainable_variables)\n",
    "        \n",
    "        # apply optimizer for both \n",
    "        # do I need to initialize two individual optimizers before? \n",
    "        self.optimizer_generator.apply_gradients(zip(gradients_generator, self.generator.trainable_variables))\n",
    "        self.optimizer_discriminator.apply_gradients(zip(gradients_discriminator, self.discriminator.trainable_variables))\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Return a dictionary mapping metric names to current value to keep track of training\n",
    "        d = {m.name: m.result() for m in self.metrics}\n",
    "        return d\n",
    "\n",
    "    @tf.function\n",
    "    def test_step(self, data):\n",
    "        \n",
    "        # same as in training but without backpropagating\n",
    "        # and printing of random noise for evaluation \n",
    "        \n",
    "        # create random noise = input to generator; size of noise vector is the size of latent space \n",
    "        noise = tf.random.normal([batch_size, 100])#????\n",
    "        \n",
    "        # loss calculation of testing data\n",
    "       \n",
    "        # discriminator sees a batch of true images and a batch of the generated images\n",
    "        generated_images = self.generator(noise, training =False)\n",
    "        true_images = data\n",
    "        # predictions\n",
    "        output_generated = self.discriminator(generated_images, training=False)\n",
    "        output_true = self.discriminator(true_images, training=False)\n",
    "        # losses \n",
    "        # loss of the discriminator is based on how well the discriminator detected fake images as fake and real images as real\n",
    "        # BCE between the discriminator’s output on the real images and all labels = 1\n",
    "        loss_true = self.loss_function(tf.ones_like(output_true), output_true)\n",
    "        # BCE between the discriminator’s output on fake images and all labels = 0\n",
    "        loss_generated = self.loss_function(tf.zeros_like(output_generated), output_generated)\n",
    "        # add together to get the resulting loss of discriminator\n",
    "        loss_discriminator = loss_true + loss_generated\n",
    "            \n",
    "        # loss of the generator is estimated by how well the generator was able to fool the discriminator\n",
    "        loss_generator = self.loss_function(tf.ones_like(output_generated), output_generated)\n",
    "            \n",
    "        # update metrics\n",
    "        self.metrics[0].update_state(loss_generator)\n",
    "        self.metrics[1].update_state(loss_discriminator)\n",
    "        \n",
    "        # Return a dictionary mapping metric names to current value to keep track of training\n",
    "        d = {m.name: m.result() for m in self.metrics}\n",
    "        \n",
    "        \n",
    "        # for evaluation, create some random latent vectors before training (see self.eval_noise) and feed them \n",
    "        # through the generator regularly. Plot the resulting images to evaluate training.\n",
    "        \n",
    "        check_generated_images = self.generator(self.eval_noise)\n",
    "        print_image(check_generated_images)\n",
    "        \n",
    "        return d \n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749a0d7b",
   "metadata": {},
   "source": [
    "### 2.3 Training\n",
    "\n",
    "* visualize your training matrices as well as generate candle images using a random seed to assert the visual quality of your GAN\n",
    "* start with 10 epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca82231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, train_ds, test_ds, epochs, train_summary_writer, test_summary_writer):\n",
    "\n",
    "    # iterate over epochs\n",
    "    for e in range(epochs):\n",
    "\n",
    "        # train steps on all batches in the training data\n",
    "        for data in tqdm.tqdm(train_ds, position=0, leave=True):\n",
    "            metrics = model.train_step(data)\n",
    "\n",
    "        # log and print training metrics\n",
    "        with train_summary_writer.as_default():\n",
    "            # for scalar metrics:\n",
    "            for metric in model.metrics:\n",
    "                    tf.summary.scalar(f\"{metric.name}\", metric.result(), step=e)\n",
    "            # alternatively, log metrics individually (allows for non-scalar metrics such as tf.keras.metrics.MeanTensor)\n",
    "            # e.g. tf.summary.image(name=\"mean_activation_layer3\", data = metrics[\"mean_activation_layer3\"],step=e)\n",
    "        \n",
    "        #print the metrics\n",
    "        print([f\"{key}: {value.numpy()}\" for (key, value) in metrics.items()])\n",
    "        \n",
    "        # 4. reset metric objects\n",
    "        model.reset_metrics()\n",
    "\n",
    "\n",
    "        # 5. evaluate on validation data\n",
    "        for data in test_ds:\n",
    "            metrics = model.test_step(data)\n",
    "        \n",
    "        # log validation metrics\n",
    "        with test_summary_writer.as_default():\n",
    "            # for scalar metrics:\n",
    "            for metric in model.metrics:\n",
    "                    tf.summary.scalar(f\"{metric.name}\", metric.result(), step=e)\n",
    "            # alternatively, log metrics individually (allows for non-scalar metrics such as tf.keras.metrics.MeanTensor)\n",
    "            # e.g. tf.summary.image(name=\"mean_activation_layer3\", data = metrics[\"mean_activation_layer3\"],step=e)\n",
    "            \n",
    "        print([f\"test_{key}: {value.numpy()}\" for (key, value) in metrics.items()])\n",
    "        # 7. reset metric objects\n",
    "        model.reset_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "524bed42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_writers(config_name):\n",
    "    \n",
    "    # Define where to save the logs\n",
    "    # along with this, you may want to save a config file with the same name so you know what the hyperparameters were used\n",
    "    # alternatively make a copy of the code that is used for later reference\n",
    "    \n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    train_log_path = f\"logs/{config_name}/{current_time}/train\"\n",
    "    test_log_path = f\"logs/{config_name}/{current_time}/test\"\n",
    "\n",
    "    # log writer for training metrics\n",
    "    train_summary_writer = tf.summary.create_file_writer(train_log_path)\n",
    "\n",
    "    # log writer for test metrics\n",
    "    test_summary_writer = tf.summary.create_file_writer(test_log_path)\n",
    "    \n",
    "    return train_summary_writer, test_summary_writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fce10bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "EPOCHS = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b52bb469",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/313 [00:09<?, ?it/s]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'Adam/Adam/update_12/ResourceApplyAdam' defined at (most recent call last):\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2880, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2935, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3134, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3337, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3397, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\berit\\AppData\\Local\\Temp\\ipykernel_12784\\3675654045.py\", line 4, in <cell line: 4>\n      training_loop(model,\n    File \"C:\\Users\\berit\\AppData\\Local\\Temp\\ipykernel_12784\\1246789580.py\", line 8, in training_loop\n      metrics = model.train_step(data)\n    File \"C:\\Users\\berit\\AppData\\Local\\Temp\\ipykernel_12784\\3509660405.py\", line 88, in train_step\n      self.optimizer_generator.apply_gradients(zip(gradients_generator, self.generator.trainable_variables))\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 738, in apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 797, in _distributed_apply\n      update_op = distribution.extended.update(\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 776, in apply_grad_to_update_var\n      update_op = self._resource_apply_dense(grad, var, **apply_kwargs)\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py\", line 177, in _resource_apply_dense\n      return tf.raw_ops.ResourceApplyAdam(\nNode: 'Adam/Adam/update_12/ResourceApplyAdam'\nvar and grad do not have the same shape[3,3,48,1] [48,1]\n\t [[{{node Adam/Adam/update_12/ResourceApplyAdam}}]] [Op:__inference_train_step_4992]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m train_summary_writer, test_summary_writer \u001b[38;5;241m=\u001b[39m create_summary_writers(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGAN_model1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m GAN()\n\u001b[1;32m----> 4\u001b[0m \u001b[43mtraining_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m              \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m              \u001b[49m\u001b[43mtest_ds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m              \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m              \u001b[49m\u001b[43mtrain_summary_writer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_summary_writer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m              \u001b[49m\u001b[43mtest_summary_writer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_summary_writer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36mtraining_loop\u001b[1;34m(model, train_ds, test_ds, epochs, train_summary_writer, test_summary_writer)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# train steps on all batches in the training data\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(train_ds, position\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m----> 8\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# log and print training metrics\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m train_summary_writer\u001b[38;5;241m.\u001b[39mas_default():\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;66;03m# for scalar metrics:\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'Adam/Adam/update_12/ResourceApplyAdam' defined at (most recent call last):\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2880, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2935, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3134, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3337, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3397, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\berit\\AppData\\Local\\Temp\\ipykernel_12784\\3675654045.py\", line 4, in <cell line: 4>\n      training_loop(model,\n    File \"C:\\Users\\berit\\AppData\\Local\\Temp\\ipykernel_12784\\1246789580.py\", line 8, in training_loop\n      metrics = model.train_step(data)\n    File \"C:\\Users\\berit\\AppData\\Local\\Temp\\ipykernel_12784\\3509660405.py\", line 88, in train_step\n      self.optimizer_generator.apply_gradients(zip(gradients_generator, self.generator.trainable_variables))\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 738, in apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 797, in _distributed_apply\n      update_op = distribution.extended.update(\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 776, in apply_grad_to_update_var\n      update_op = self._resource_apply_dense(grad, var, **apply_kwargs)\n    File \"C:\\Users\\berit\\AppData\\Local\\Continuum\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py\", line 177, in _resource_apply_dense\n      return tf.raw_ops.ResourceApplyAdam(\nNode: 'Adam/Adam/update_12/ResourceApplyAdam'\nvar and grad do not have the same shape[3,3,48,1] [48,1]\n\t [[{{node Adam/Adam/update_12/ResourceApplyAdam}}]] [Op:__inference_train_step_4992]"
     ]
    }
   ],
   "source": [
    "train_summary_writer, test_summary_writer = create_summary_writers(\"GAN_model1\")\n",
    "model = GAN()\n",
    "\n",
    "training_loop(model, \n",
    "              train_ds=train_ds, \n",
    "              test_ds=test_ds, \n",
    "              epochs= EPOCHS, \n",
    "              train_summary_writer=train_summary_writer, \n",
    "              test_summary_writer=test_summary_writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bb7c69",
   "metadata": {},
   "source": [
    "var and grad do not have the same shape[3,3,48,1] [48,1] -> why?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iannwtf",
   "language": "python",
   "name": "iannwtf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
