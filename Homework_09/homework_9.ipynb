{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import time\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Reshape, MaxPooling2D, GlobalAveragePooling2D, UpSampling2D, BatchNormalization\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Prepare the Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "categories = [line.rstrip(b'\\n') for line in urllib.request.urlopen('https://raw.githubusercontent.com/googlecreativelab/quickdraw-dataset/master/categories.txt')]\n",
    "print(categories[:10])\n",
    "category = 'candle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a folder to download the original drawings into.\n",
    "# We chose to use the numpy format : 1x784 pixel vectors, with values going from 0 (white) to 255 (black). We reshape them later to 28x28 grids and normalize the pixel intensity to [-1, 1]\n",
    "\n",
    "if not os.path.isdir('npy_files'):\n",
    "    os.mkdir('npy_files')\n",
    "    \n",
    "url = f'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/{category}.npy'  \n",
    "urllib.request.urlretrieve(url, f'npy_files/{category}.npy')\n",
    "\n",
    "images = np.load(f'npy_files/{category}.npy')\n",
    "print(f'{len(images)} images to train on')\n",
    "\n",
    "# You can limit the amount of images you use for training by setting :\n",
    "train_images = images[:10000]\n",
    "# You should also define a smaller subset of the images for testing..\n",
    "# TODO\n",
    "\n",
    "# Notice that this to numpy format contains 1x784 pixel vectors, with values going from 0 (white) to 255 (black). We reshape them later to 28x28 grids and normalize the pixel intensity to [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(images):\n",
    "    batch_size = 32\n",
    "    shuffle_size = 1000\n",
    "    #Construct a tf.Data.Dataset object\n",
    "    data = tf.data.Dataset.from_tensor_slices(images)\n",
    "    data = data.map(lambda x: tf.cast(x, tf.float32))\n",
    "    data= data.map(lambda x: x / 128 - 1)\n",
    "    #Normalize: Bring the images’ values into a sensible range. (-1, 1)\n",
    "    data= data.map(lambda x: tf.reshape(x, (28, 28, 1)))\n",
    "    #The images come as (1,784) pixel arrays. You should make sure to reshape 28x28x1\n",
    "\n",
    "\n",
    "    data.cache()\n",
    "    data = data.shuffle(shuffle_size)\n",
    "    data = data.batch(batch_size)\n",
    "    data = data.prefetch(tf.data.AUTOTUNE)\n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Disciminator(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self): \n",
    "        super().__init__()\n",
    "        self._activation_function_name = 'relu'\n",
    "        self._output_activation_function_name = 'sigmoid'\n",
    "\n",
    "        self.convolutional_layer_1 = Conv2D(filters=24, kernel_size=3, padding='same', activation=self._activation_function_name) \n",
    "        self.convolutional_layer_2 = Conv2D(filters=24, kernel_size=3, padding='same', activation=self._activation_function_name) \n",
    "        self.pooling = MaxPooling2D(pool_size=2, strides=2)\n",
    "\n",
    "        self.convolutional_layer_3 = Conv2D(filters=48, kernel_size=3, padding='same', activation=self._activation_function_name) \n",
    "        self.convolutional_layer_4 = Conv2D(filters=48, kernel_size=3, padding='same', activation=self._activation_function_name)\n",
    "        self.global_pool = GlobalAveragePooling2D()\n",
    "\n",
    "        self.out = Dense(1, activation=self._output_activation_function_name)\n",
    "\n",
    "    def call(self, x, training): #need to add batchnormalization still \n",
    "        input = self.convolutional_layer_1(input)\n",
    "        input = self.convolutional_layer_2(input)\n",
    "        input = self.pooling(input)\n",
    "        input = self.convolutional_layer_3(input)\n",
    "        input = self.convolutional_layer_4(input)\n",
    "        input = self.global_pool(input)\n",
    "        input = self.out(input)\n",
    "        return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self): \n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "    def call(self, x, training): "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Training \n",
    "\n",
    "In each training step, the generator is fed with random noise and creates\n",
    "images from it. The discriminator sees a batch of true images and a batch of the generated\n",
    "images. The loss of the discriminator is based on how well the discriminator\n",
    "detected fake images as fake and real images as real. The loss of the generator is estimated by how well the generator was able to\n",
    "fool the discriminator. The more images the discriminator falsely classified as real, the better our generator works and the smaller the Binary Cross Entropy loss between the discriminator’s predictions and all labels as true=1\n",
    "\n",
    "check footnotes 5-11 for tips"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28e91920f599e44071da7b36c0d9862a45581326e40810d4c828eb96f38d732c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
